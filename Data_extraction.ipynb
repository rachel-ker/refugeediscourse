{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import re\n",
    "import nltk\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will extract top tweets for the past 10 years. 100 top tweets will be extracted each month on the specified topic for past 10 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_tweets(topic, end_date, years=13):\n",
    "    columns = ['id', 'url', 'author', 'retweets', 'favorites', 'mentions', 'hashtags', 'geo', 'time', 'text']\n",
    "    text_query = topic\n",
    "    \n",
    "    # convert the end_date string to the datetime object\n",
    "    end_date_datetime = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "    # This section is to create a list of datetime objects that are 1 month apart going backwards\n",
    "    date_range = [end_date_datetime]\n",
    "    total_days = int(365 * years)\n",
    "    \n",
    "    prior_date = end_date_datetime\n",
    "    \n",
    "    while total_days > 0:\n",
    "        prior_date = prior_date - relativedelta(days=1)\n",
    "        date_range.append(prior_date)\n",
    "        total_days -= 1\n",
    "        \n",
    "    # Convert the elements in the list from datetime objects to string\n",
    "    date_range_string = [twitter_date.strftime('%Y-%m-%d') for twitter_date in date_range][::-1]\n",
    "    print(\"Start querying data...\")\n",
    "    \n",
    "    # Initialize an empty list to store dataframe from each iteration\n",
    "    compiled_tweets_df = pd.DataFrame(columns=columns)\n",
    "    \n",
    "    \n",
    "    for i in range(len(date_range_string)-1):\n",
    "        tweetCriteria = got3.manager\\\n",
    "                .TweetCriteria()\\\n",
    "                .setQuerySearch(text_query)\\\n",
    "                .setLang('en')\\\n",
    "                .setSince(date_range_string[i])\\\n",
    "                .setUntil(date_range_string[i+1])\\\n",
    "                .setTopTweets(True)\\\n",
    "                .setMaxTweets(4)\\\n",
    "                .setEmoji(\"unicode\")\n",
    "\n",
    "        tweets = got3.manager.TweetManager.getTweets(tweetCriteria)\n",
    "\n",
    "        text_tweets = [[tweet.id, tweet.permalink, tweet.username, tweet.retweets, \n",
    "                tweet.favorites, tweet.mentions, tweet.hashtags, tweet.geo, \n",
    "                tweet.date, tweet.text] for tweet in tweets]\n",
    "\n",
    "        sample_tweets = pd.DataFrame(text_tweets, columns=columns)\n",
    "        compiled_tweets_df = pd.concat([compiled_tweets_df, sample_tweets])\n",
    "        print(\"Query between {} and {} complete!\".format(date_range_string[i], date_range_string[i+1]))\n",
    "        print(\"Pause the operation...\")\n",
    "        time.sleep(2.5) # pause for 2.5 seconds to avoid server crashing\n",
    "        print(\"Begin new iteration...\")\n",
    "        \n",
    "    return compiled_tweets_df # concatenate the list of dataframe into a single dataframe\n",
    "    print(\"Operation complete!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start querying data...\n",
      "Query between 2019-11-25 and 2019-11-26 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-11-26 and 2019-11-27 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-11-27 and 2019-11-28 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-11-28 and 2019-11-29 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-11-29 and 2019-11-30 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-11-30 and 2019-12-01 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-01 and 2019-12-02 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-02 and 2019-12-03 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-03 and 2019-12-04 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-04 and 2019-12-05 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-05 and 2019-12-06 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-06 and 2019-12-07 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-07 and 2019-12-08 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-08 and 2019-12-09 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-09 and 2019-12-10 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-10 and 2019-12-11 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-11 and 2019-12-12 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-12 and 2019-12-13 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-13 and 2019-12-14 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-14 and 2019-12-15 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-15 and 2019-12-16 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-16 and 2019-12-17 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-17 and 2019-12-18 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-18 and 2019-12-19 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-19 and 2019-12-20 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-20 and 2019-12-21 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-21 and 2019-12-22 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-22 and 2019-12-23 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-23 and 2019-12-24 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-24 and 2019-12-25 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-25 and 2019-12-26 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-26 and 2019-12-27 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-27 and 2019-12-28 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-28 and 2019-12-29 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-29 and 2019-12-30 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n",
      "Query between 2019-12-30 and 2019-12-31 complete!\n",
      "Pause the operation...\n",
      "Begin new iteration...\n"
     ]
    }
   ],
   "source": [
    "tweets = get_tweets(\"immigra\", \"2019-12-31\", 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Some Florida prison guards to be sworn as ICE ...\n",
       "0    Issued by the U.S. Immigration and Customs Enf...\n",
       "0    We're honored to be awarded Immigration Attorn...\n",
       "0    We are grateful to assist those whose dream it...\n",
       "0    Are you scheduled for an interview at a local ...\n",
       "0    Millions of petitions & applications are delay...\n",
       "0    Apparently democratic voters aren’t so sure. I...\n",
       "0    Are you traveling this holiday season? If so, ...\n",
       "0    Immigration Attorneys, LLP attorney Sara Barto...\n",
       "0    There are certain required #naturalization ele...\n",
       "0    This great country is based on freedom. With s...\n",
       "0    “Stephen, thought you might like to see sample...\n",
       "0    Today, we remember the battle and the brave pe...\n",
       "0    We have four offices nationwide to serve you. ...\n",
       "0    The story of your immigration journey matters ...\n",
       "0    Immigration forms and requirements evolve quic...\n",
       "0    Krista Eyler, an Immigration Attorneys, LLP at...\n",
       "0    We're honored to be awarded Immigration Attorn...\n",
       "0    Delays in the adjudications process affect mil...\n",
       "0    #DrHabib_Review Mr. Menju Toshihiro id the man...\n",
       "0    You’ve filed your marriage-based green card ap...\n",
       "0    I dare some one to run by that line screaming ...\n",
       "0    You deserve a competent and trustworthy team t...\n",
       "0    USCIS has dramatically changed the agency’s co...\n",
       "0    The Immigration Attorneys LLP team works dilig...\n",
       "0    The immigration process can seem puzzling at t...\n",
       "0    \"Fanboys & cheerleaders\" not accepting of fact...\n",
       "0    Read @immigra_results: You deserve a competent...\n",
       "0    ↳ ❥ Dwen Updates | ⊹~`° RT DaShanneStokes: Man...\n",
       "0    Have you received a Notice to Appear from the ...\n",
       "0    Thank you for being a part of our joy in 2019....\n",
       "0    It's “H-1B Season.” Now is the time to speak t...\n",
       "0    Our newsletter features articles and topics th...\n",
       "0    Reaching us quickly and easily through our onl...\n",
       "0    GRACE... marvels at God's flexibility with the...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.index = range(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Issued by the U.S. Immigration and Customs Enforcement's (ICE) and Removal Operations (ERO), these announcements detail enforcement activities and resulting apprehensions. Read more here: https://www.aila.org/infonet/ice-announcements-of-enforcement-actions #2019 #immatty #immigration #immigrationresults #citizenship\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"text\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text) # remove url\n",
    "    text = text.lower() # convert text to lower case\n",
    "    text = text.split()\n",
    "    text = [i for i in text if not i.startswith(\"#\")]\n",
    "    text = ' '.join(text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove punctuations\n",
    "\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"text\"] = tweets[\"text\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"time\"] = pd.to_datetime(tweets[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>author</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>geo</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1199067809273147392</td>\n",
       "      <td>https://twitter.com/MiamiPlow/status/119906780...</td>\n",
       "      <td>MiamiPlow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>#Miami #FL</td>\n",
       "      <td></td>\n",
       "      <td>2019-11-25 20:50:17+00:00</td>\n",
       "      <td>some florida prison guards to be sworn as ice ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1199056441870618626</td>\n",
       "      <td>https://twitter.com/immigra_results/status/119...</td>\n",
       "      <td>immigra_results</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>#immatty #immigration #immigrationresults #cit...</td>\n",
       "      <td></td>\n",
       "      <td>2019-11-25 20:05:07+00:00</td>\n",
       "      <td>we are grateful to clients who tell us how we ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1199038356954451968</td>\n",
       "      <td>https://twitter.com/RePEc_NEP_EUR/status/11990...</td>\n",
       "      <td>RePEc_NEP_EUR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019-11-25 18:53:16+00:00</td>\n",
       "      <td>does integration policy improve labour market ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1199420095635832832</td>\n",
       "      <td>https://twitter.com/immigra_results/status/119...</td>\n",
       "      <td>immigra_results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>#immatty #immigration #immigrationresults #cit...</td>\n",
       "      <td></td>\n",
       "      <td>2019-11-26 20:10:09+00:00</td>\n",
       "      <td>issued by the us immigration and customs enfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1199141541379497984</td>\n",
       "      <td>https://twitter.com/RePEc_NEP_MIG/status/11991...</td>\n",
       "      <td>RePEc_NEP_MIG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2019-11-26 01:43:17+00:00</td>\n",
       "      <td>does integration policy improve labour market ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                                url           author retweets favorites mentions                                           hashtags geo                      time                                               text\n",
       "0  1199067809273147392  https://twitter.com/MiamiPlow/status/119906780...        MiamiPlow        0         0                                                  #Miami #FL     2019-11-25 20:50:17+00:00  some florida prison guards to be sworn as ice ...\n",
       "1  1199056441870618626  https://twitter.com/immigra_results/status/119...  immigra_results        1         1           #immatty #immigration #immigrationresults #cit...     2019-11-25 20:05:07+00:00  we are grateful to clients who tell us how we ...\n",
       "2  1199038356954451968  https://twitter.com/RePEc_NEP_EUR/status/11990...    RePEc_NEP_EUR        0         0                                                                 2019-11-25 18:53:16+00:00  does integration policy improve labour market ...\n",
       "3  1199420095635832832  https://twitter.com/immigra_results/status/119...  immigra_results        0         0           #immatty #immigration #immigrationresults #cit...     2019-11-26 20:10:09+00:00  issued by the us immigration and customs enfor...\n",
       "4  1199141541379497984  https://twitter.com/RePEc_NEP_MIG/status/11991...    RePEc_NEP_MIG        0         0                                                                 2019-11-26 01:43:17+00:00  does integration policy improve labour market ..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Timestamp' object has no attribute 'dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-be4b4b0c6d93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"time\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtz_localize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Timestamp' object has no attribute 'dt'"
     ]
    }
   ],
   "source": [
    "tweets[\"time\"][1].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Excel does not support datetimes with timezones. Please ensure that datetimes are timezone unaware before writing to Excel.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-aab8d21470e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"demonstration.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[1;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[0;32m   2254\u001b[0m             \u001b[0mstartcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2255\u001b[0m             \u001b[0mfreeze_panes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2256\u001b[1;33m             \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2257\u001b[0m         )\n\u001b[0;32m   2258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0mstartrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mstartcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             \u001b[0mfreeze_panes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m         )\n\u001b[0;32m    741\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mneed_save\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py\u001b[0m in \u001b[0;36mwrite_cells\u001b[1;34m(self, cells, sheet_name, startrow, startcol, freeze_panes)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mwks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcells\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m             \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value_with_fmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36mget_formatted_cells\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_formatted_cells\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\io\\formats\\excel.py\u001b[0m in \u001b[0;36m_format_value\u001b[1;34m(self, val)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tzinfo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             raise ValueError(\n\u001b[1;32m--> 437\u001b[1;33m                 \u001b[1;34m\"Excel does not support datetimes with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m                 \u001b[1;34m\"timezones. Please ensure that datetimes \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;34m\"are timezone unaware before writing to Excel.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Excel does not support datetimes with timezones. Please ensure that datetimes are timezone unaware before writing to Excel."
     ]
    }
   ],
   "source": [
    "tweets.to_excel(\"demonstration.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(\"immigration_tweets_data_example.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us rallies urge immigration reform protesters say bushs proposed overhaul of immigra'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us rallies urge immigration reform protesters say bushs proposed overhaul of immigra'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"immigration_tweets_data_example.csv\").iloc[:, -1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
