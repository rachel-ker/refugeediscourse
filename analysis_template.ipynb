{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Functions for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim#For word2vec, etc\n",
    "from gensim.models import ldaseqmodel\n",
    "\n",
    "import lucem_illud_2020\n",
    "\n",
    "import numpy as np #For arrays\n",
    "import pandas as pd #Gives us DataFrames\n",
    "import scipy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt #For graphics\n",
    "import wordcloud\n",
    "import seaborn as sns #makes our plots look nicer\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics.pairwise #For cosine similarity\n",
    "import sklearn.manifold #For T-SNE\n",
    "import sklearn.decomposition #For PCA\n",
    "\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "\n",
    "import networkx as nx\n",
    "import copy\n",
    "\n",
    "#This 'magic' command makes the plots work better\n",
    "#in the notebook, don't use it outside of a notebook.\n",
    "#Also you can ignore the warning\n",
    "%matplotlib inline\n",
    "\n",
    "import os #For looking through files\n",
    "import os.path #For managing file paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "rename_dict = {'id': 'text_id',\n",
    "               'word_counts': 'word_count',\n",
    "               'author': 'source',\n",
    "              }\n",
    "\n",
    "filepath=\"/Users/rachelker/Documents/UChic MSCAPP/Curriculum/2019-20 Winter/Computational Content Analysis/Project/twitterpolicydiscourse/data/\"\n",
    "coca_data = pd.read_csv(filepath + \"refugee_coca_foranalysis.csv\").drop(columns=['subgen'])\n",
    "tweet_data = pd.read_csv(filepath + \"twitter_data_to_concat.csv\").drop(columns=['Unnamed: 0']).rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48993 48993\n"
     ]
    }
   ],
   "source": [
    "# to concatenate coca and tweet data\n",
    "data = pd.concat([coca_data, tweet_data], ignore_index=True)\n",
    "print(len(data['text_id'].unique()), len(data)) #check that id is unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and normalize words\n",
    "data['tokenized_words'] = data['text'].apply(lambda x: lucem_illud_2020.word_tokenize(x))\n",
    "data['normalized_words'] = data['tokenized_words'].apply(lambda x: lucem_illud_2020.normalizeTokens(x))\n",
    "data['normalized_words_POS'] = [lucem_illud_2020.spacy_pos(t) for t in data['text']]\n",
    "\n",
    "\n",
    "# tokenize and normalize sentences\n",
    "data['tokenized_sents'] = data['text'].apply(lambda x: [lucem_illud_2020.word_tokenize(s) for s in lucem_illud_2020.sent_tokenize(x)])\n",
    "data['normalized_sents'] = data['tokenized_sents'].apply(lambda x: [lucem_illud_2020.normalizeTokens(s) for s in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(\"data/data_normalized.pkl\")\n",
    "# saving to csv does not return list type\n",
    "#data.to_csv(\"data/data_normalized.csv\", index=False)\n",
    "#data = pd.read_csv(\"data/data_normalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data/data_normalized.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word/Phrase Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency Distribution\n",
    "fdist = nltk.FreqDist([w for w in data['normalized_words'].sum()])\n",
    "freq = pd.DataFrame.from_dict(fdist, orient='index', columns=['count'])\n",
    "freq = freq.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>132529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refugee</th>\n",
       "      <td>56176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>say</th>\n",
       "      <td>51158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>45925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>38552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>31616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>29493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>27550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>know</th>\n",
       "      <td>27113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>23114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "s        132529\n",
       "refugee   56176\n",
       "say       51158\n",
       "not       45925\n",
       "people    38552\n",
       "think     31616\n",
       "go        29493\n",
       "year      27550\n",
       "know      27113\n",
       "come      23114"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get context\n",
    "post_text = nltk.Text(data['tokenized_words'].sum())\n",
    "index = nltk.text.ConcordanceIndex(post_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 26654 matches:\n",
      "university and himself a 1960 cuban refugee mariels were driven less by politic\n",
      "he wall photo black white below the refugee center where the suarezes and other\n",
      "toon at second glance i look like a refugee farmer but careful examination reve\n",
      "s guerrillas as we pass a family of refugee indians from the highlands dressed \n",
      "ople creating a massive and complex refugee problem half a million saudis egypt\n",
      "tuation is of particular concern to refugee organizations if baghdad succeeds i\n",
      " an unusual briefing on the kuwaiti refugee dilemma and the palestinian aspect \n",
      "at they had better shut down contra refugee camps before michael dukakis became\n",
      "ndcutting why not the fanjuls are a refugee family he says the economy of the c\n",
      "ttee on the panama canal the aid to refugee chinese intellectuals among the bet\n",
      "ms fell over themselves to hire any refugee from drexel s corporate finance dep\n",
      "soviet army barracks into emergency refugee camps german officials speak uneasi\n",
      "tino was often there as was another refugee from rome the architect and sculpto\n",
      "was biochemist ernst chain a german refugee florey believed that many of the an\n",
      "ly thatch of hair california shirts refugee in marin county instead he is a tex\n",
      " at a time when he lived there as a refugee from the problems in mainz back in \n",
      "eum under the title britain and the refugee crisis 19331947 make this point wit\n",
      "near rudesheim in 1902 arrived as a refugee in 1933 hallgarten later a wellknow\n",
      "victor gollancz noel coward and the refugee hermann rauschning the lists were n\n",
      "ittle sympathy for rincon a spanish refugee and rebel a traitor to both his sov\n",
      "themselves out to be leaders in the refugee community first the younger son and\n",
      " looked on ireland from the crowded refugee towns on the continent and saw that\n",
      "was a catalyst in an experience all refugee communities encounter whether to pr\n",
      "h the sticky red mud of an oklahoma refugee camp during a bitter white winter f\n",
      "of facilitating was not a political refugee washington insisted but a common cr\n"
     ]
    }
   ],
   "source": [
    "index.print_concordance('refugee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 29522 matches:\n",
      "w in the water jammed with 80 or so refugees some of them just released from cub\n",
      "torm a documentary about the mariel refugees fate as he gazes at the hangar the \n",
      "ghter s future making a will mariel refugees belies the stigma that the cuban bo\n",
      "lift s end in september some mariel refugees had committed murders burglaries or\n",
      "where the suarezes and other mariel refugees section investing expanding petroch\n",
      "uments and aerospace parts many are refugees from hightax california and unfortu\n",
      "tytown later they met three teenage refugees from honduras the last surviving ma\n",
      "y center casa oscar romero when the refugees brought out guitars the students le\n",
      "ese newer immigrants were political refugees they were for the most part poor pe\n",
      "5744 people mostly eastern european refugees then living in germany and austria \n",
      "gulations provided for thousands of refugees from hungary after the hungarian ri\n",
      "ericans including relatively recent refugees or emigres or escapees from eastern\n",
      "ctober after interviewing scores of refugees in the region amnesty international\n",
      "king in kuwait as domestic servants refugees who have survived iraqi torture and\n",
      "the leaders of the resistance other refugees say the resistance is led by civili\n",
      "tunate are the roughly 150000 asian refugees from bangladesh india pakistan sri \n",
      "fficial put it the us committee for refugees reported that two months after the \n",
      "l more than 75000 nonnative kuwaiti refugees most of them asians in illstaffed c\n",
      "camps in jordan approximately 60000 refugees crossed into syria 40000 into turke\n",
      "ching relations with tehran the new refugees as well as the halfmillion refugees\n",
      "refugees as well as the halfmillion refugees from the iraniraq war including 900\n",
      "eted by the arrival of thousands of refugees from the civil war in neighboring m\n",
      "ke those who came in 196979 they re refugees most would be going to brooklyn if \n",
      "he georgianborn ephraim gur today s refugees may finally who came in the seventi\n",
      "rations of sanctuary for salvadoran refugees a political movement designed to fo\n"
     ]
    }
   ],
   "source": [
    "index.print_concordance('refugees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so_some mariel_fate mariel_belies mariel_had mariel_section are_from\n",
      "teenage_from the_brought political_they european_then of_from\n",
      "recent_or of_in servants_who other_say asian_from for_reported\n",
      "kuwaiti_most 60000_crossed new_as\n"
     ]
    }
   ],
   "source": [
    "# common context\n",
    "post_text.common_contexts(['refugees'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelker/.pyenv/versions/3.8.1/lib/python3.8/site-packages/nltk/draw/__init__.py:15: UserWarning: nltk.draw package not loaded (please install Tkinter library).\n",
      "  warnings.warn(\"nltk.draw package not loaded \" \"(please install Tkinter library).\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lexical Dispersion Plot\n",
    "sns.reset_orig() #Seaborn messes with this plot, disabling it\n",
    "post_text.dispersion_plot(['refugee', 'refugees'])\n",
    "sns.set() #Re-enabling seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Most common POS\n",
    "def get_most_common_POS(data, years, genre=None):\n",
    "    for yr in years:\n",
    "        if genre:\n",
    "            yearly = data[(data['genre']==genre) & (data['year']==yr)]\n",
    "        else:\n",
    "            yearly = data[data['year']==yr]\n",
    "        freqdist_POStoWord = nltk.ConditionalFreqDist((p, w) for w, p in yearly['normalized_words_POS'].sum())\n",
    "        print(yr)\n",
    "        print(\"Most Common Nouns\")\n",
    "        print(freqdist_POStoWord['NN'].most_common(10))\n",
    "        print()\n",
    "        print(\"Most Common Adj\")\n",
    "        print(freqdist_POStoWord['JJ'].most_common(10))\n",
    "        print()\n",
    "        print(\"Most Common Verbs\")\n",
    "        print(freqdist_POStoWord['VB'].most_common(10))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MAG', 'SPOK', 'NEWS', 'twitter'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = sorted(data['year'].unique())\n",
    "genres = data['genre'].unique()\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990\n",
      "Most Common Nouns\n",
      "[('time', 960), ('government', 933), ('today', 874), ('world', 786), ('country', 783), ('war', 689), ('way', 662), ('year', 565), ('mrlehrer', 535), ('day', 433)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 1195), ('many', 821), ('new', 763), ('american', 621), ('last', 602), ('good', 571), ('iraqi', 564), ('military', 530), ('first', 495), ('soviet', 486)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 3592), ('have', 1320), ('do', 824), ('get', 708), ('go', 554), ('think', 488), ('take', 481), ('make', 479), ('say', 445), ('see', 404)]\n",
      "\n",
      "1991\n",
      "Most Common Nouns\n",
      "[('war', 1339), ('time', 1246), ('government', 1092), ('today', 1072), ('country', 925), ('way', 892), ('world', 750), ('year', 657), ('mrlehrer', 578), ('day', 567)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 1439), ('many', 1076), ('american', 835), ('iraqi', 834), ('new', 826), ('last', 811), ('good', 770), ('first', 673), ('political', 648), ('own', 568)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 4783), ('have', 1974), ('do', 1201), ('get', 883), ('go', 874), ('think', 692), ('say', 692), ('take', 674), ('make', 642), ('see', 641)]\n",
      "\n",
      "1992\n",
      "Most Common Nouns\n",
      "[('time', 802), ('country', 669), ('government', 667), ('today', 637), ('year', 544), ('way', 510), ('world', 503), ('percent', 475), ('war', 412), ('family', 391)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 908), ('many', 765), ('new', 627), ('last', 594), ('good', 503), ('first', 498), ('political', 472), ('american', 472), ('little', 368), ('own', 310)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2861), ('have', 1196), ('do', 794), ('get', 670), ('go', 531), ('make', 460), ('take', 414), ('think', 394), ('see', 391), ('say', 381)]\n",
      "\n",
      "1993\n",
      "Most Common Nouns\n",
      "[('time', 878), ('war', 698), ('today', 660), ('way', 650), ('year', 622), ('world', 617), ('government', 608), ('country', 561), ('man', 465), ('day', 387)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 965), ('many', 791), ('new', 667), ('last', 633), ('american', 521), ('good', 510), ('first', 493), ('political', 438), ('own', 328), ('little', 326)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 3150), ('have', 1246), ('do', 895), ('get', 627), ('go', 508), ('make', 484), ('think', 447), ('see', 440), ('take', 419), ('say', 413)]\n",
      "\n",
      "1994\n",
      "Most Common Nouns\n",
      "[('time', 1191), ('government', 1020), ('country', 884), ('today', 855), ('way', 835), ('mrlehrer', 766), ('world', 730), ('year', 714), ('policy', 699), ('president', 677)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 1355), ('new', 1021), ('many', 972), ('last', 799), ('american', 756), ('good', 737), ('first', 676), ('political', 563), ('little', 482), ('military', 479)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 4514), ('have', 1875), ('do', 1239), ('get', 1027), ('go', 823), ('think', 639), ('say', 627), ('make', 626), ('see', 623), ('let', 613)]\n",
      "\n",
      "1995\n",
      "Most Common Nouns\n",
      "[('time', 560), ('world', 473), ('war', 448), ('government', 439), ('year', 434), ('way', 420), ('today', 413), ('peace', 387), ('country', 380), ('day', 308)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 728), ('many', 531), ('new', 502), ('first', 433), ('american', 413), ('last', 372), ('good', 326), ('own', 281), ('bosnian', 271), ('political', 262)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2181), ('have', 822), ('do', 521), ('get', 399), ('go', 364), ('take', 310), ('say', 308), ('make', 295), ('let', 274), ('see', 263)]\n",
      "\n",
      "1996\n",
      "Most Common Nouns\n",
      "[('time', 704), ('today', 605), ('government', 539), ('year', 528), ('way', 524), ('country', 439), ('war', 366), ('world', 335), ('life', 334), ('day', 310)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 723), ('new', 586), ('many', 531), ('last', 512), ('american', 490), ('first', 465), ('good', 440), ('military', 312), ('political', 311), ('own', 270)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2456), ('have', 1064), ('do', 750), ('get', 555), ('go', 430), ('make', 372), ('say', 339), ('take', 327), ('think', 321), ('see', 316)]\n",
      "\n",
      "1997\n",
      "Most Common Nouns\n",
      "[('time', 499), ('government', 386), ('war', 372), ('way', 337), ('year', 319), ('country', 319), ('king', 298), ('today', 275), ('world', 264), ('part', 256)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 558), ('new', 468), ('many', 412), ('last', 317), ('first', 314), ('political', 263), ('american', 256), ('good', 235), ('same', 208), ('own', 203)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1683), ('have', 611), ('do', 375), ('get', 340), ('go', 234), ('think', 226), ('make', 226), ('see', 221), ('take', 212), ('say', 164)]\n",
      "\n",
      "1998\n",
      "Most Common Nouns\n",
      "[('time', 500), ('way', 332), ('king', 303), ('world', 296), ('day', 289), ('man', 285), ('government', 284), ('year', 274), ('country', 259), ('today', 252)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 450), ('many', 424), ('last', 360), ('new', 317), ('first', 309), ('good', 294), ('little', 220), ('american', 193), ('few', 185), ('next', 175)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1437), ('have', 651), ('do', 424), ('get', 299), ('go', 290), ('make', 244), ('see', 227), ('take', 212), ('say', 212), ('know', 207)]\n",
      "\n",
      "1999\n",
      "Most Common Nouns\n",
      "[('war', 783), ('time', 774), ('way', 560), ('country', 460), ('family', 439), ('world', 431), ('lot', 408), ('today', 406), ('air', 393), ('government', 371)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 818), ('many', 615), ('last', 479), ('good', 467), ('first', 453), ('new', 422), ('american', 385), ('own', 356), ('little', 338), ('military', 324)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2723), ('have', 1086), ('do', 723), ('get', 586), ('go', 546), ('say', 446), ('make', 418), ('see', 389), ('think', 367), ('take', 361)]\n",
      "\n",
      "2000\n",
      "Most Common Nouns\n",
      "[('time', 475), ('government', 445), ('war', 385), ('world', 367), ('peace', 314), ('end', 308), ('way', 302), ('year', 287), ('country', 263), ('day', 259)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 541), ('many', 447), ('new', 419), ('last', 362), ('palestinian', 302), ('first', 298), ('israeli', 288), ('political', 281), ('few', 202), ('own', 201)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1468), ('have', 559), ('do', 276), ('get', 274), ('go', 237), ('see', 229), ('make', 218), ('take', 210), ('begin', 204), ('say', 181)]\n",
      "\n",
      "2001\n",
      "Most Common Nouns\n",
      "[('time', 749), ('world', 566), ('war', 511), ('country', 465), ('way', 450), ('year', 444), ('government', 382), ('life', 381), ('day', 355), ('lot', 310)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 661), ('many', 551), ('new', 465), ('last', 461), ('first', 417), ('good', 356), ('american', 345), ('military', 309), ('same', 281), ('little', 280)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2084), ('have', 858), ('do', 558), ('get', 420), ('go', 365), ('see', 337), ('make', 313), ('take', 304), ('say', 260), ('know', 249)]\n",
      "\n",
      "2002\n",
      "Most Common Nouns\n",
      "[('time', 588), ('world', 566), ('war', 517), ('way', 433), ('country', 401), ('director', 379), ('government', 374), ('day', 361), ('life', 356), ('year', 356)]\n",
      "\n",
      "Most Common Adj\n",
      "[('israeli', 671), ('other', 661), ('many', 557), ('new', 519), ('palestinian', 500), ('last', 375), ('first', 348), ('american', 285), ('own', 281), ('military', 272)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1847), ('have', 691), ('do', 413), ('go', 353), ('get', 342), ('make', 313), ('see', 298), ('take', 289), ('say', 216), ('know', 190)]\n",
      "\n",
      "2003\n",
      "Most Common Nouns\n",
      "[('war', 697), ('time', 521), ('world', 429), ('government', 393), ('way', 360), ('day', 351), ('director', 349), ('year', 330), ('violence', 294), ('country', 290)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 544), ('many', 473), ('new', 373), ('first', 348), ('american', 333), ('last', 314), ('iraqi', 290), ('good', 275), ('little', 221), ('own', 203)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1736), ('have', 621), ('do', 369), ('get', 364), ('go', 300), ('make', 245), ('see', 224), ('take', 201), ('say', 199), ('think', 194)]\n",
      "\n",
      "2004\n",
      "Most Common Nouns\n",
      "[('time', 434), ('war', 376), ('director', 369), ('way', 301), ('country', 269), ('government', 269), ('world', 268), ('life', 236), ('story', 230), ('year', 230)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 427), ('many', 386), ('new', 383), ('first', 293), ('last', 283), ('american', 249), ('good', 204), ('palestinian', 186), ('own', 171), ('iraqi', 168)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1241), ('have', 498), ('do', 275), ('get', 231), ('see', 213), ('take', 200), ('go', 196), ('make', 189), ('know', 179), ('say', 162)]\n",
      "\n",
      "2005\n",
      "Most Common Nouns\n",
      "[('time', 614), ('world', 371), ('war', 360), ('way', 343), ('city', 342), ('government', 340), ('life', 322), ('today', 320), ('day', 319), ('family', 318)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 583), ('other', 542), ('new', 411), ('first', 361), ('last', 354), ('good', 328), ('little', 262), ('american', 256), ('great', 222), ('few', 220)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1892), ('have', 836), ('get', 554), ('do', 472), ('go', 360), ('see', 348), ('take', 316), ('make', 274), ('know', 247), ('help', 214)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "Most Common Nouns\n",
      "[('time', 721), ('world', 471), ('country', 459), ('government', 453), ('way', 448), ('day', 441), ('today', 417), ('war', 370), ('city', 370), ('family', 345)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 669), ('many', 627), ('new', 571), ('last', 412), ('israeli', 387), ('first', 381), ('good', 329), ('american', 300), ('little', 281), ('own', 275)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2129), ('have', 804), ('get', 545), ('do', 481), ('see', 397), ('go', 386), ('take', 366), ('make', 323), ('say', 254), ('come', 249)]\n",
      "\n",
      "2007\n",
      "Most Common Nouns\n",
      "[('refugee', 623), ('time', 534), ('war', 469), ('government', 438), ('world', 418), ('camp', 413), ('year', 348), ('country', 345), ('today', 340), ('way', 336)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 499), ('new', 421), ('many', 418), ('iraqi', 356), ('last', 303), ('first', 286), ('palestinian', 271), ('american', 257), ('good', 253), ('political', 231)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1682), ('have', 719), ('do', 470), ('get', 357), ('go', 294), ('make', 272), ('see', 259), ('take', 238), ('say', 224), ('think', 204)]\n",
      "\n",
      "2008\n",
      "Most Common Nouns\n",
      "[('refugee', 1405), ('camp', 379), ('time', 344), ('government', 286), ('war', 236), ('world', 227), ('today', 225), ('day', 224), ('life', 216), ('family', 214)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 346), ('new', 346), ('other', 308), ('iraqi', 299), ('last', 212), ('first', 203), ('good', 196), ('little', 151), ('own', 142), ('american', 142)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 941), ('have', 387), ('get', 216), ('do', 212), ('go', 199), ('see', 172), ('take', 168), ('make', 166), ('help', 150), ('know', 114)]\n",
      "\n",
      "2009\n",
      "Most Common Nouns\n",
      "[('refugee', 2168), ('camp', 494), ('time', 344), ('war', 331), ('government', 311), ('life', 273), ('family', 266), ('world', 237), ('today', 234), ('day', 228)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 402), ('other', 374), ('many', 326), ('first', 216), ('last', 207), ('good', 206), ('israeli', 201), ('young', 175), ('palestinian', 169), ('american', 164)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1073), ('have', 402), ('do', 242), ('get', 209), ('see', 193), ('help', 192), ('make', 188), ('go', 183), ('know', 160), ('take', 157)]\n",
      "\n",
      "2010\n",
      "Most Common Nouns\n",
      "[('refugee', 1589), ('time', 426), ('camp', 365), ('country', 337), ('day', 304), ('government', 304), ('today', 299), ('year', 281), ('world', 267), ('life', 266)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 428), ('many', 365), ('other', 358), ('last', 271), ('first', 233), ('good', 233), ('few', 165), ('own', 163), ('american', 157), ('little', 156)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1094), ('have', 348), ('get', 254), ('do', 252), ('help', 196), ('see', 189), ('go', 188), ('take', 171), ('make', 171), ('know', 126)]\n",
      "\n",
      "2011\n",
      "Most Common Nouns\n",
      "[('refugee', 1256), ('camp', 581), ('time', 447), ('day', 407), ('today', 405), ('government', 404), ('war', 337), ('way', 333), ('country', 333), ('world', 333)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 497), ('other', 486), ('many', 370), ('last', 293), ('first', 265), ('good', 260), ('palestinian', 234), ('political', 189), ('syrian', 182), ('military', 177)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1351), ('have', 502), ('do', 354), ('get', 334), ('see', 294), ('make', 267), ('go', 246), ('help', 223), ('take', 203), ('say', 176)]\n",
      "\n",
      "2012\n",
      "Most Common Nouns\n",
      "[('refugee', 1334), ('time', 551), ('government', 544), ('today', 524), ('camp', 513), ('country', 428), ('way', 421), ('day', 390), ('war', 378), ('year', 347)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 606), ('other', 526), ('new', 508), ('many', 461), ('last', 369), ('first', 333), ('good', 322), ('little', 248), ('own', 235), ('political', 226)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1775), ('have', 732), ('do', 504), ('get', 415), ('go', 340), ('see', 324), ('make', 314), ('take', 299), ('say', 278), ('know', 238)]\n",
      "\n",
      "2013\n",
      "Most Common Nouns\n",
      "[('refugee', 1165), ('time', 755), ('today', 588), ('government', 540), ('country', 533), ('world', 523), ('day', 521), ('way', 472), ('lot', 440), ('camp', 440)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 1017), ('other', 732), ('new', 649), ('many', 571), ('last', 441), ('good', 414), ('first', 403), ('american', 351), ('little', 323), ('great', 295)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2509), ('have', 981), ('do', 659), ('get', 616), ('go', 494), ('see', 467), ('make', 421), ('take', 376), ('let', 329), ('say', 313)]\n",
      "\n",
      "2014\n",
      "Most Common Nouns\n",
      "[('refugee', 1099), ('time', 913), ('government', 748), ('country', 738), ('way', 655), ('today', 623), ('war', 583), ('world', 576), ('lot', 560), ('day', 551)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 811), ('many', 766), ('new', 748), ('syrian', 682), ('last', 517), ('good', 507), ('first', 481), ('american', 426), ('political', 351), ('little', 345)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2924), ('have', 1157), ('do', 850), ('get', 738), ('see', 553), ('take', 493), ('go', 492), ('make', 468), ('say', 411), ('think', 390)]\n",
      "\n",
      "2015\n",
      "Most Common Nouns\n",
      "[('refugee', 1107), ('time', 956), ('today', 777), ('country', 749), ('way', 725), ('world', 696), ('government', 643), ('lot', 629), ('state', 585), ('year', 544)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 1055), ('new', 902), ('many', 863), ('syrian', 831), ('last', 585), ('good', 579), ('first', 520), ('political', 481), ('american', 403), ('little', 382)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 3266), ('have', 1293), ('do', 947), ('get', 784), ('go', 616), ('take', 586), ('make', 561), ('say', 549), ('see', 541), ('know', 460)]\n",
      "\n",
      "2016\n",
      "Most Common Nouns\n",
      "[('refugee', 987), ('crisis', 152), ('camp', 127), ('amp', 100), ('world', 96), ('child', 94), ('today', 77), ('year', 71), ('country', 67), ('family', 65)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 549), ('muslim', 98), ('new', 85), ('german', 58), ('many', 58), ('first', 54), ('young', 35), ('safe', 34), ('good', 32), ('own', 32)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 226), ('help', 105), ('take', 81), ('do', 55), ('have', 45), ('get', 44), ('stop', 42), ('bring', 38), ('go', 37), ('keep', 32)]\n",
      "\n",
      "2017\n",
      "Most Common Nouns\n",
      "[('refugee', 1097), ('crisis', 153), ('amp', 141), ('camp', 104), ('rohingya', 102), ('world', 98), ('trump', 85), ('country', 83), ('child', 80), ('family', 78)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 251), ('new', 129), ('many', 89), ('muslim', 88), ('good', 59), ('last', 57), ('manus', 53), ('other', 45), ('first', 44), ('safe', 41)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 241), ('help', 109), ('take', 68), ('get', 53), ('have', 52), ('go', 52), ('do', 49), ('ve', 46), ('stop', 45), ('see', 42)]\n",
      "\n",
      "2018\n",
      "Most Common Nouns\n",
      "[('refugee', 1379), ('amp', 237), ('country', 200), ('asylum', 177), ('camp', 175), ('world', 160), ('crisis', 144), ('today', 142), ('year', 133), ('rohingya', 132)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 236), ('new', 138), ('many', 133), ('last', 99), ('palestinian', 97), ('other', 96), ('first', 93), ('human', 79), ('safe', 70), ('muslim', 65)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 469), ('help', 129), ('have', 103), ('do', 102), ('take', 95), ('get', 89), ('make', 68), ('go', 66), ('see', 60), ('stop', 50)]\n",
      "\n",
      "2019\n",
      "Most Common Nouns\n",
      "[('refugee', 1299), ('amp', 282), ('country', 258), ('asylum', 237), ('today', 186), ('family', 176), ('camp', 163), ('government', 147), ('world', 147), ('crisis', 139)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 189), ('new', 147), ('many', 146), ('human', 126), ('other', 121), ('first', 95), ('last', 92), ('own', 84), ('safe', 76), ('medical', 76)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 560), ('have', 144), ('do', 126), ('help', 121), ('get', 109), ('make', 92), ('take', 92), ('go', 82), ('see', 70), ('stop', 63)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_most_common_POS(data, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990\n",
      "Most Common Nouns\n",
      "[('time', 207), ('year', 176), ('world', 171), ('photo', 147), ('state', 145), ('government', 139), ('city', 135), ('country', 127), ('family', 119), ('money', 116)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 253), ('new', 223), ('many', 201), ('such', 159), ('american', 157), ('own', 123), ('first', 119), ('last', 117), ('foreign', 111), ('national', 107)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 674), ('have', 224), ('do', 116), ('get', 99), ('take', 90), ('make', 80), ('go', 70), ('see', 68), ('keep', 50), ('come', 43)]\n",
      "\n",
      "1991\n",
      "Most Common Nouns\n",
      "[('time', 210), ('war', 157), ('world', 135), ('year', 117), ('photo', 114), ('way', 103), ('man', 94), ('day', 91), ('government', 88), ('history', 86)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 209), ('new', 158), ('last', 146), ('many', 145), ('first', 144), ('american', 115), ('own', 111), ('few', 103), ('little', 98), ('black', 97)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 471), ('have', 199), ('do', 100), ('get', 87), ('take', 79), ('make', 75), ('go', 72), ('see', 58), ('come', 57), ('give', 36)]\n",
      "\n",
      "1992\n",
      "Most Common Nouns\n",
      "[('time', 174), ('world', 149), ('country', 127), ('government', 119), ('year', 116), ('way', 111), ('war', 100), ('life', 93), ('water', 87), ('work', 79)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 208), ('many', 194), ('american', 162), ('political', 119), ('first', 115), ('new', 114), ('last', 106), ('own', 99), ('such', 91), ('good', 81)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 557), ('have', 202), ('do', 81), ('get', 73), ('take', 64), ('make', 60), ('go', 50), ('see', 49), ('say', 39), ('find', 38)]\n",
      "\n",
      "1993\n",
      "Most Common Nouns\n",
      "[('world', 166), ('time', 133), ('year', 117), ('war', 108), ('government', 97), ('way', 88), ('company', 82), ('life', 80), ('refugee', 74), ('country', 68)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 144), ('many', 121), ('new', 119), ('first', 108), ('political', 99), ('last', 87), ('social', 70), ('few', 69), ('american', 64), ('own', 63)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 415), ('have', 143), ('do', 69), ('make', 63), ('get', 61), ('go', 58), ('see', 48), ('take', 46), ('come', 40), ('help', 34)]\n",
      "\n",
      "1994\n",
      "Most Common Nouns\n",
      "[('world', 206), ('war', 172), ('year', 166), ('state', 161), ('time', 155), ('life', 145), ('government', 140), ('country', 128), ('percent', 128), ('way', 119)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 279), ('other', 263), ('many', 216), ('american', 167), ('such', 158), ('political', 134), ('first', 131), ('last', 126), ('economic', 120), ('own', 110)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 778), ('have', 224), ('do', 114), ('make', 81), ('get', 70), ('take', 66), ('go', 59), ('come', 49), ('see', 46), ('give', 44)]\n",
      "\n",
      "1995\n",
      "Most Common Nouns\n",
      "[('time', 173), ('world', 169), ('war', 149), ('family', 148), ('church', 138), ('year', 128), ('way', 118), ('government', 115), ('life', 113), ('work', 112)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 264), ('many', 203), ('american', 177), ('new', 169), ('black', 142), ('first', 132), ('such', 118), ('own', 110), ('bosnian', 107), ('last', 104)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 581), ('have', 208), ('do', 99), ('get', 87), ('take', 82), ('make', 71), ('go', 67), ('see', 65), ('find', 46), ('come', 44)]\n",
      "\n",
      "1996\n",
      "Most Common Nouns\n",
      "[('contact', 285), ('hunting', 194), ('dept', 181), ('box', 133), ('fishing', 130), ('time', 113), ('life', 86), ('war', 81), ('way', 80), ('world', 78)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 133), ('other', 128), ('american', 99), ('national', 85), ('first', 79), ('military', 78), ('political', 77), ('such', 77), ('foreign', 77), ('new', 76)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 304), ('have', 107), ('do', 84), ('get', 57), ('make', 56), ('go', 50), ('see', 38), ('give', 35), ('take', 34), ('know', 33)]\n",
      "\n",
      "1997\n",
      "Most Common Nouns\n",
      "[('time', 139), ('war', 112), ('way', 97), ('world', 97), ('military', 89), ('government', 75), ('year', 71), ('family', 68), ('company', 67), ('life', 65)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 165), ('new', 129), ('many', 128), ('own', 96), ('military', 95), ('first', 88), ('such', 82), ('same', 81), ('american', 76), ('few', 66)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 465), ('have', 138), ('get', 80), ('do', 77), ('see', 65), ('make', 50), ('take', 43), ('know', 40), ('go', 39), ('keep', 28)]\n",
      "\n",
      "1998\n",
      "Most Common Nouns\n",
      "[('time', 116), ('world', 94), ('way', 91), ('war', 71), ('life', 70), ('day', 59), ('year', 57), ('man', 56), ('piano', 55), ('work', 53)]\n",
      "\n",
      "Most Common Adj\n",
      "[('first', 105), ('new', 103), ('many', 95), ('other', 93), ('human', 74), ('black', 74), ('little', 69), ('own', 64), ('last', 63), ('few', 57)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 293), ('have', 120), ('see', 66), ('get', 62), ('do', 58), ('make', 54), ('go', 52), ('take', 42), ('come', 35), ('find', 32)]\n",
      "\n",
      "1999\n",
      "Most Common Nouns\n",
      "[('time', 130), ('government', 104), ('world', 102), ('year', 99), ('war', 99), ('country', 92), ('way', 83), ('oil', 82), ('life', 78), ('day', 78)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 158), ('new', 116), ('many', 108), ('first', 92), ('last', 85), ('big', 79), ('few', 77), ('own', 74), ('good', 69), ('american', 64)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 382), ('have', 123), ('make', 77), ('do', 58), ('get', 57), ('take', 45), ('know', 37), ('go', 36), ('find', 29), ('see', 29)]\n",
      "\n",
      "2000\n",
      "Most Common Nouns\n",
      "[('war', 129), ('time', 101), ('world', 96), ('day', 75), ('government', 65), ('way', 64), ('city', 51), ('work', 51), ('year', 46), ('country', 41)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 116), ('many', 95), ('french', 71), ('black', 69), ('new', 69), ('first', 64), ('few', 58), ('own', 58), ('american', 58), ('political', 57)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 235), ('have', 70), ('see', 54), ('do', 50), ('get', 43), ('make', 37), ('take', 35), ('go', 32), ('know', 29), ('let', 21)]\n",
      "\n",
      "2001\n",
      "Most Common Nouns\n",
      "[('time', 198), ('world', 178), ('year', 176), ('war', 149), ('way', 125), ('life', 115), ('country', 108), ('family', 89), ('day', 79), ('place', 73)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 194), ('new', 144), ('many', 144), ('first', 116), ('last', 105), ('little', 97), ('american', 89), ('good', 89), ('own', 87), ('few', 79)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 500), ('have', 213), ('do', 141), ('get', 97), ('make', 79), ('see', 75), ('go', 70), ('say', 56), ('take', 54), ('think', 46)]\n",
      "\n",
      "2002\n",
      "Most Common Nouns\n",
      "[('world', 195), ('war', 156), ('time', 124), ('country', 103), ('way', 97), ('life', 87), ('water', 79), ('government', 77), ('day', 76), ('place', 65)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 165), ('many', 157), ('new', 144), ('military', 94), ('american', 89), ('first', 78), ('such', 74), ('few', 68), ('economic', 64), ('own', 63)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 418), ('have', 123), ('see', 67), ('do', 66), ('take', 63), ('go', 56), ('make', 53), ('get', 52), ('help', 37), ('know', 29)]\n",
      "\n",
      "2003\n",
      "Most Common Nouns\n",
      "[('world', 192), ('year', 157), ('time', 137), ('photo', 137), ('color', 125), ('family', 122), ('government', 115), ('water', 104), ('life', 98), ('day', 96)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 189), ('new', 154), ('many', 149), ('first', 134), ('last', 94), ('such', 89), ('former', 74), ('own', 73), ('next', 73), ('american', 71)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 489), ('have', 134), ('get', 68), ('do', 67), ('make', 65), ('go', 56), ('take', 53), ('find', 51), ('help', 49), ('see', 46)]\n",
      "\n",
      "2004\n",
      "Most Common Nouns\n",
      "[('war', 114), ('city', 95), ('time', 81), ('world', 76), ('way', 75), ('peace', 67), ('life', 60), ('power', 58), ('intelligence', 58), ('photo', 58)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 156), ('other', 129), ('new', 97), ('first', 77), ('american', 72), ('few', 64), ('last', 57), ('local', 57), ('own', 56), ('religious', 51)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 265), ('have', 87), ('do', 45), ('make', 41), ('find', 40), ('take', 34), ('see', 33), ('get', 31), ('give', 23), ('go', 23)]\n",
      "\n",
      "2005\n",
      "Most Common Nouns\n",
      "[('war', 161), ('world', 106), ('time', 105), ('government', 75), ('city', 65), ('man', 56), ('population', 56), ('part', 53), ('percent', 53), ('way', 53)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 132), ('other', 129), ('nuclear', 96), ('first', 85), ('american', 83), ('military', 75), ('great', 73), ('korean', 71), ('new', 67), ('few', 61)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 360), ('have', 144), ('do', 78), ('make', 65), ('take', 56), ('get', 50), ('see', 48), ('say', 39), ('know', 36), ('go', 33)]\n",
      "\n",
      "2006\n",
      "Most Common Nouns\n",
      "[('time', 160), ('city', 153), ('world', 150), ('government', 117), ('country', 116), ('way', 107), ('day', 106), ('fire', 98), ('life', 89), ('man', 88)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 177), ('many', 163), ('other', 158), ('own', 91), ('last', 90), ('political', 88), ('american', 87), ('same', 81), ('first', 79), ('old', 77)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 531), ('have', 195), ('do', 93), ('make', 86), ('get', 84), ('take', 72), ('go', 70), ('see', 65), ('come', 65), ('know', 50)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007\n",
      "Most Common Nouns\n",
      "[('world', 174), ('war', 159), ('time', 144), ('city', 133), ('country', 127), ('year', 115), ('government', 111), ('water', 107), ('day', 101), ('life', 94)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 160), ('new', 142), ('many', 127), ('first', 108), ('own', 93), ('such', 88), ('last', 88), ('few', 81), ('global', 79), ('american', 75)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 459), ('have', 150), ('do', 110), ('get', 81), ('make', 75), ('see', 73), ('take', 69), ('help', 59), ('say', 51), ('go', 51)]\n",
      "\n",
      "2008\n",
      "Most Common Nouns\n",
      "[('time', 118), ('war', 114), ('water', 87), ('government', 85), ('life', 82), ('world', 80), ('homer', 77), ('year', 74), ('day', 73), ('country', 72)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 126), ('many', 113), ('new', 112), ('first', 83), ('own', 72), ('american', 62), ('last', 58), ('military', 58), ('iraqi', 55), ('such', 54)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 301), ('have', 110), ('do', 52), ('make', 52), ('take', 44), ('get', 41), ('go', 38), ('see', 37), ('come', 27), ('help', 26)]\n",
      "\n",
      "2009\n",
      "Most Common Nouns\n",
      "[('time', 115), ('war', 105), ('family', 98), ('life', 92), ('way', 90), ('mother', 79), ('show', 74), ('idf', 73), ('world', 70), ('church', 69)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 109), ('many', 102), ('new', 85), ('good', 80), ('israeli', 78), ('first', 66), ('own', 63), ('jewish', 59), ('little', 58), ('few', 52)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 297), ('have', 119), ('do', 65), ('make', 60), ('say', 52), ('see', 50), ('get', 50), ('know', 45), ('take', 36), ('give', 29)]\n",
      "\n",
      "2010\n",
      "Most Common Nouns\n",
      "[('time', 197), ('wife', 146), ('year', 129), ('war', 125), ('class', 101), ('email', 101), ('world', 99), ('life', 94), ('way', 91), ('climate', 88)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 143), ('other', 139), ('new', 139), ('last', 123), ('first', 105), ('good', 82), ('few', 79), ('next', 66), ('own', 61), ('american', 61)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 396), ('have', 117), ('get', 62), ('make', 61), ('do', 57), ('see', 54), ('take', 53), ('go', 45), ('know', 38), ('work', 35)]\n",
      "\n",
      "2011\n",
      "Most Common Nouns\n",
      "[('war', 142), ('time', 110), ('life', 92), ('way', 89), ('world', 89), ('marion', 89), ('sidebar', 87), ('family', 84), ('day', 75), ('peace', 73)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 134), ('many', 93), ('new', 93), ('first', 88), ('few', 69), ('british', 67), ('military', 58), ('inca', 57), ('american', 56), ('such', 51)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 323), ('have', 110), ('do', 68), ('make', 54), ('see', 54), ('go', 44), ('take', 43), ('know', 29), ('get', 29), ('think', 26)]\n",
      "\n",
      "2012\n",
      "Most Common Nouns\n",
      "[('war', 152), ('time', 108), ('world', 69), ('way', 67), ('government', 61), ('country', 55), ('city', 53), ('man', 51), ('life', 48), ('day', 48)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 104), ('many', 103), ('first', 89), ('new', 70), ('jewish', 50), ('political', 47), ('few', 47), ('human', 46), ('old', 43), ('own', 42)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 209), ('have', 71), ('do', 43), ('take', 41), ('get', 35), ('make', 34), ('see', 32), ('help', 30), ('find', 28), ('go', 26)]\n",
      "\n",
      "2013\n",
      "Most Common Nouns\n",
      "[('time', 160), ('war', 116), ('city', 104), ('day', 104), ('country', 101), ('world', 97), ('king', 93), ('year', 91), ('state', 91), ('mail', 89)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 184), ('many', 152), ('new', 115), ('first', 94), ('political', 74), ('young', 72), ('few', 71), ('little', 69), ('last', 66), ('such', 65)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 432), ('have', 136), ('do', 95), ('make', 70), ('go', 54), ('take', 51), ('see', 50), ('get', 49), ('help', 37), ('become', 32)]\n",
      "\n",
      "2014\n",
      "Most Common Nouns\n",
      "[('time', 206), ('government', 174), ('war', 164), ('family', 151), ('world', 148), ('country', 147), ('year', 146), ('state', 145), ('day', 143), ('school', 132)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 255), ('other', 232), ('new', 177), ('first', 129), ('such', 115), ('young', 113), ('own', 102), ('few', 101), ('american', 98), ('last', 92)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 506), ('have', 195), ('see', 102), ('do', 100), ('get', 90), ('make', 82), ('take', 70), ('go', 69), ('help', 55), ('come', 53)]\n",
      "\n",
      "2015\n",
      "Most Common Nouns\n",
      "[('world', 229), ('time', 220), ('state', 186), ('government', 154), ('war', 153), ('life', 152), ('country', 150), ('year', 149), ('city', 146), ('way', 142)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 264), ('new', 259), ('other', 251), ('political', 150), ('such', 148), ('few', 143), ('first', 142), ('last', 123), ('jewish', 120), ('own', 99)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 699), ('have', 227), ('do', 129), ('make', 107), ('see', 94), ('get', 93), ('take', 92), ('go', 82), ('find', 54), ('give', 53)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre = 'MAG'\n",
    "genre_years = sorted(data[data['genre']==genre]['year'].unique())\n",
    "get_most_common_POS(data, genre_years, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990\n",
      "Most Common Nouns\n",
      "[('today', 699), ('government', 630), ('time', 623), ('country', 541), ('mrlehrer', 535), ('world', 505), ('way', 466), ('war', 453), ('lot', 306), ('fact', 294)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 715), ('many', 431), ('good', 420), ('new', 392), ('military', 360), ('last', 360), ('american', 355), ('iraqi', 330), ('soviet', 308), ('first', 270)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2416), ('have', 962), ('do', 616), ('get', 525), ('think', 427), ('go', 420), ('say', 367), ('make', 330), ('let', 319), ('take', 304)]\n",
      "\n",
      "1991\n",
      "Most Common Nouns\n",
      "[('war', 945), ('today', 893), ('time', 862), ('government', 751), ('country', 710), ('way', 646), ('mrlehrer', 578), ('king', 544), ('world', 475), ('question', 468)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 942), ('many', 637), ('good', 631), ('iraqi', 573), ('american', 556), ('last', 514), ('new', 488), ('first', 399), ('political', 392), ('military', 385)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 3620), ('have', 1579), ('do', 989), ('go', 716), ('get', 713), ('think', 630), ('say', 616), ('let', 550), ('take', 508), ('see', 508)]\n",
      "\n",
      "1992\n",
      "Most Common Nouns\n",
      "[('today', 520), ('time', 493), ('country', 381), ('government', 373), ('way', 327), ('lot', 312), ('year', 306), ('president', 281), ('percent', 281), ('economy', 257)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 485), ('many', 390), ('good', 383), ('last', 341), ('new', 331), ('first', 300), ('little', 265), ('political', 244), ('american', 233), ('next', 178)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1847), ('have', 830), ('do', 638), ('get', 520), ('go', 429), ('think', 343), ('make', 327), ('say', 314), ('let', 301), ('see', 297)]\n",
      "\n",
      "1993\n",
      "Most Common Nouns\n",
      "[('today', 553), ('time', 548), ('way', 459), ('country', 365), ('year', 351), ('world', 309), ('man', 307), ('government', 302), ('war', 297), ('lot', 282)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 565), ('many', 423), ('good', 390), ('last', 358), ('new', 342), ('american', 305), ('first', 266), ('little', 218), ('political', 210), ('much', 187)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2118), ('have', 889), ('do', 700), ('get', 476), ('think', 384), ('go', 380), ('say', 347), ('see', 327), ('make', 321), ('take', 281)]\n",
      "\n",
      "1994\n",
      "Most Common Nouns\n",
      "[('time', 878), ('mrlehrer', 766), ('today', 730), ('government', 702), ('way', 637), ('country', 635), ('president', 601), ('policy', 546), ('health', 522), ('lot', 494)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 915), ('good', 614), ('new', 573), ('many', 548), ('last', 541), ('american', 515), ('first', 423), ('little', 352), ('political', 335), ('military', 319)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 3251), ('have', 1484), ('do', 1067), ('get', 874), ('go', 678), ('think', 589), ('let', 570), ('say', 565), ('see', 522), ('make', 490)]\n",
      "\n",
      "1995\n",
      "Most Common Nouns\n",
      "[('today', 280), ('time', 260), ('mrlehrer', 239), ('way', 223), ('country', 197), ('year', 178), ('lot', 168), ('president', 165), ('peace', 163), ('government', 157)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 284), ('good', 203), ('many', 179), ('american', 174), ('new', 171), ('first', 169), ('last', 141), ('right', 115), ('important', 107), ('great', 106)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1116), ('have', 479), ('do', 350), ('get', 249), ('say', 244), ('go', 238), ('let', 217), ('think', 188), ('make', 169), ('see', 165)]\n",
      "\n",
      "1996\n",
      "Most Common Nouns\n",
      "[('today', 461), ('time', 443), ('way', 364), ('year', 320), ('government', 311), ('country', 274), ('lot', 246), ('mrlehrer', 244), ('president', 239), ('part', 204)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 432), ('good', 334), ('new', 327), ('last', 297), ('american', 293), ('many', 272), ('first', 215), ('right', 183), ('next', 176), ('important', 165)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1637), ('have', 777), ('do', 584), ('get', 435), ('go', 324), ('say', 285), ('think', 281), ('let', 272), ('make', 262), ('see', 244)]\n",
      "\n",
      "1997\n",
      "Most Common Nouns\n",
      "[('king', 276), ('time', 249), ('way', 187), ('country', 169), ('today', 166), ('part', 165), ('lot', 157), ('margaretwarner', 156), ('year', 133), ('government', 129)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 236), ('new', 187), ('good', 156), ('last', 148), ('many', 125), ('first', 122), ('american', 117), ('political', 115), ('great', 103), ('important', 94)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 856), ('have', 344), ('do', 236), ('get', 208), ('think', 181), ('go', 154), ('see', 134), ('make', 132), ('take', 128), ('say', 121)]\n",
      "\n",
      "1998\n",
      "Most Common Nouns\n",
      "[('king', 290), ('time', 248), ('way', 184), ('man', 183), ('lot', 179), ('today', 158), ('dole', 157), ('country', 138), ('day', 138), ('something', 135)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 198), ('good', 195), ('many', 183), ('last', 167), ('great', 99), ('new', 97), ('little', 96), ('first', 88), ('long', 86), ('next', 77)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 790), ('have', 413), ('do', 308), ('get', 184), ('go', 183), ('think', 155), ('say', 152), ('know', 147), ('let', 145), ('make', 134)]\n",
      "\n",
      "1999\n",
      "Most Common Nouns\n",
      "[('time', 476), ('war', 460), ('way', 391), ('lot', 364), ('question', 299), ('today', 291), ('ground', 274), ('air', 271), ('country', 271), ('point', 263)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 457), ('many', 365), ('good', 352), ('last', 265), ('first', 236), ('american', 221), ('military', 204), ('little', 198), ('own', 192), ('important', 191)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1846), ('have', 791), ('do', 557), ('get', 451), ('go', 437), ('say', 388), ('think', 317), ('let', 304), ('see', 300), ('make', 287)]\n",
      "\n",
      "2000\n",
      "Most Common Nouns\n",
      "[('end', 239), ('time', 220), ('government', 216), ('videotape', 216), ('today', 197), ('camera', 191), ('peace', 186), ('world', 185), ('way', 148), ('video', 137)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 231), ('new', 203), ('many', 191), ('palestinian', 191), ('last', 185), ('israeli', 176), ('political', 146), ('first', 127), ('russian', 121), ('former', 102)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 779), ('have', 353), ('begin', 191), ('do', 165), ('get', 159), ('go', 147), ('see', 134), ('say', 126), ('make', 125), ('take', 124)]\n",
      "\n",
      "2001\n",
      "Most Common Nouns\n",
      "[('time', 304), ('war', 209), ('country', 201), ('way', 199), ('today', 179), ('lot', 178), ('world', 177), ('king', 169), ('government', 160), ('part', 130)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 210), ('many', 196), ('rich', 188), ('good', 162), ('last', 161), ('military', 156), ('american', 140), ('first', 128), ('new', 127), ('same', 115)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 898), ('have', 398), ('do', 276), ('go', 212), ('get', 195), ('see', 174), ('take', 162), ('say', 156), ('know', 151), ('think', 138)]\n",
      "\n",
      "2002\n",
      "Most Common Nouns\n",
      "[('time', 275), ('world', 229), ('way', 221), ('war', 208), ('today', 208), ('lot', 195), ('day', 166), ('country', 151), ('end', 147), ('government', 144)]\n",
      "\n",
      "Most Common Adj\n",
      "[('israeli', 315), ('other', 262), ('palestinian', 251), ('unidentified', 204), ('many', 202), ('new', 167), ('last', 156), ('own', 131), ('good', 125), ('first', 115)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 915), ('have', 358), ('do', 247), ('get', 218), ('go', 209), ('see', 159), ('say', 154), ('make', 148), ('take', 146), ('think', 128)]\n",
      "\n",
      "2003\n",
      "Most Common Nouns\n",
      "[('war', 379), ('time', 255), ('way', 182), ('today', 160), ('government', 159), ('lot', 153), ('world', 149), ('country', 145), ('day', 132), ('something', 131)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 215), ('american', 180), ('many', 178), ('good', 155), ('iraqi', 148), ('last', 129), ('unintelligible', 120), ('new', 117), ('first', 115), ('unidentifiedmale', 107)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 870), ('have', 355), ('do', 242), ('get', 223), ('go', 174), ('think', 150), ('say', 146), ('see', 136), ('make', 128), ('let', 106)]\n",
      "\n",
      "2004\n",
      "Most Common Nouns\n",
      "[('time', 206), ('war', 167), ('way', 151), ('today', 148), ('country', 146), ('lot', 146), ('story', 127), ('government', 127), ('morning', 110), ('end', 103)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 164), ('new', 148), ('unidentified', 138), ('last', 137), ('good', 117), ('first', 105), ('many', 101), ('american', 100), ('unintelligible', 97), ('iraqi', 88)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 627), ('have', 274), ('do', 160), ('go', 136), ('get', 133), ('see', 130), ('know', 119), ('take', 111), ('say', 110), ('think', 102)]\n",
      "\n",
      "2005\n",
      "Most Common Nouns\n",
      "[('time', 384), ('today', 238), ('lot', 237), ('water', 216), ('day', 214), ('way', 210), ('world', 204), ('life', 196), ('country', 195), ('something', 182)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 324), ('other', 250), ('good', 225), ('new', 210), ('first', 210), ('last', 200), ('little', 183), ('unidentified', 174), ('great', 118), ('american', 116)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1196), ('have', 558), ('get', 427), ('do', 347), ('go', 278), ('see', 214), ('take', 208), ('know', 176), ('come', 162), ('say', 155)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "Most Common Nouns\n",
      "[('time', 415), ('today', 300), ('lot', 259), ('way', 253), ('day', 246), ('world', 244), ('country', 240), ('king', 207), ('government', 201), ('war', 193)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 304), ('many', 246), ('israeli', 235), ('new', 217), ('good', 211), ('last', 199), ('first', 191), ('little', 171), ('next', 151), ('american', 134)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1126), ('have', 495), ('get', 382), ('do', 299), ('see', 287), ('go', 247), ('take', 225), ('say', 176), ('make', 172), ('let', 166)]\n",
      "\n",
      "2007\n",
      "Most Common Nouns\n",
      "[('time', 271), ('war', 228), ('today', 226), ('government', 195), ('way', 180), ('lot', 159), ('king', 149), ('world', 143), ('something', 140), ('country', 137)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 240), ('many', 187), ('good', 142), ('new', 134), ('last', 134), ('american', 133), ('political', 124), ('iraqi', 98), ('same', 94), ('big', 85)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 839), ('have', 442), ('do', 287), ('get', 204), ('go', 178), ('think', 152), ('see', 149), ('say', 144), ('know', 138), ('make', 132)]\n",
      "\n",
      "2008\n",
      "Most Common Nouns\n",
      "[('today', 109), ('time', 90), ('hemmer', 90), ('government', 80), ('lot', 59), ('health', 55), ('money', 54), ('way', 52), ('part', 50), ('country', 50)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 95), ('other', 70), ('good', 64), ('new', 63), ('last', 46), ('big', 38), ('same', 38), ('little', 34), ('much', 33), ('different', 30)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 321), ('have', 130), ('do', 92), ('get', 90), ('go', 76), ('say', 66), ('see', 63), ('let', 61), ('make', 60), ('think', 55)]\n",
      "\n",
      "2009\n",
      "Most Common Nouns\n",
      "[('time', 122), ('amanpour', 120), ('today', 119), ('lot', 86), ('way', 77), ('country', 72), ('war', 70), ('health', 64), ('something', 61), ('world', 61)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 122), ('unidentifiedmale', 110), ('many', 93), ('young', 81), ('new', 79), ('last', 65), ('american', 59), ('good', 58), ('next', 55), ('first', 51)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 387), ('have', 171), ('do', 115), ('go', 93), ('see', 81), ('know', 77), ('get', 76), ('say', 66), ('think', 64), ('make', 59)]\n",
      "\n",
      "2010\n",
      "Most Common Nouns\n",
      "[('today', 153), ('time', 121), ('lot', 108), ('country', 107), ('government', 106), ('way', 94), ('money', 73), ('world', 69), ('tax', 68), ('king', 62)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 122), ('good', 90), ('new', 84), ('many', 83), ('last', 66), ('little', 62), ('big', 53), ('few', 49), ('own', 48), ('local', 45)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 358), ('do', 134), ('have', 130), ('get', 129), ('go', 87), ('make', 73), ('see', 63), ('take', 62), ('think', 58), ('say', 56)]\n",
      "\n",
      "2011\n",
      "Most Common Nouns\n",
      "[('today', 247), ('time', 240), ('government', 208), ('lot', 200), ('way', 167), ('tonight', 163), ('country', 147), ('day', 144), ('state', 125), ('man', 125)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 221), ('new', 177), ('good', 172), ('last', 161), ('many', 145), ('first', 123), ('right', 92), ('political', 84), ('little', 84), ('big', 81)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 645), ('have', 296), ('get', 224), ('do', 215), ('see', 173), ('make', 156), ('go', 142), ('think', 128), ('let', 120), ('say', 120)]\n",
      "\n",
      "2012\n",
      "Most Common Nouns\n",
      "[('today', 379), ('time', 328), ('lot', 298), ('government', 275), ('way', 265), ('president', 231), ('country', 219), ('percent', 210), ('year', 198), ('campaign', 197)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 275), ('new', 249), ('last', 238), ('good', 232), ('many', 211), ('big', 181), ('first', 154), ('little', 150), ('right', 148), ('next', 139)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1125), ('have', 554), ('do', 378), ('get', 304), ('go', 248), ('say', 245), ('see', 223), ('make', 222), ('think', 191), ('take', 179)]\n",
      "\n",
      "2013\n",
      "Most Common Nouns\n",
      "[('time', 469), ('today', 415), ('lot', 399), ('government', 343), ('way', 324), ('world', 299), ('country', 294), ('president', 274), ('something', 267), ('day', 260)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 434), ('new', 313), ('good', 294), ('many', 281), ('last', 264), ('american', 236), ('right', 232), ('little', 207), ('big', 195), ('first', 194)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1640), ('have', 733), ('do', 495), ('get', 491), ('go', 360), ('see', 345), ('make', 292), ('let', 290), ('say', 267), ('take', 257)]\n",
      "\n",
      "2014\n",
      "Most Common Nouns\n",
      "[('time', 552), ('lot', 501), ('country', 439), ('government', 435), ('today', 434), ('way', 418), ('president', 330), ('world', 307), ('something', 303), ('isis', 300)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 428), ('good', 352), ('new', 349), ('last', 317), ('many', 314), ('american', 256), ('big', 243), ('first', 236), ('right', 219), ('little', 214)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 1940), ('have', 817), ('do', 631), ('get', 556), ('see', 378), ('go', 336), ('take', 330), ('say', 329), ('make', 315), ('think', 310)]\n",
      "\n",
      "2015\n",
      "Most Common Nouns\n",
      "[('time', 567), ('today', 539), ('lot', 536), ('way', 495), ('something', 411), ('country', 396), ('thing', 341), ('president', 337), ('isis', 329), ('government', 315)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 619), ('good', 429), ('new', 381), ('many', 381), ('last', 344), ('right', 263), ('first', 259), ('great', 259), ('big', 249), ('american', 240)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 2055), ('have', 905), ('do', 721), ('get', 584), ('say', 461), ('go', 449), ('see', 372), ('know', 364), ('think', 361), ('take', 356)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre = 'SPOK'\n",
    "genre_years = sorted(data[data['genre']==genre]['year'].unique())\n",
    "get_most_common_POS(data, genre_years, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990\n",
      "Most Common Nouns\n",
      "[('government', 164), ('time', 130), ('war', 126), ('today', 118), ('country', 115), ('world', 110), ('year', 105), ('city', 103), ('life', 90), ('group', 88)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 227), ('many', 189), ('iraqi', 189), ('new', 148), ('last', 125), ('soviet', 114), ('american', 109), ('first', 106), ('such', 104), ('military', 96)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 502), ('have', 134), ('do', 92), ('take', 87), ('get', 84), ('make', 69), ('go', 64), ('help', 58), ('know', 52), ('see', 45)]\n",
      "\n",
      "1991\n",
      "Most Common Nouns\n",
      "[('government', 253), ('war', 237), ('time', 174), ('year', 153), ('border', 146), ('way', 143), ('world', 140), ('peace', 131), ('country', 130), ('today', 125)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 294), ('other', 288), ('iraqi', 247), ('new', 180), ('american', 164), ('political', 161), ('kurdish', 160), ('last', 151), ('first', 130), ('military', 127)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 692), ('have', 196), ('do', 112), ('take', 87), ('go', 86), ('make', 83), ('get', 83), ('see', 75), ('help', 58), ('come', 45)]\n",
      "\n",
      "1992\n",
      "Most Common Nouns\n",
      "[('government', 175), ('country', 161), ('time', 135), ('world', 126), ('war', 124), ('year', 122), ('percent', 116), ('city', 104), ('state', 94), ('school', 93)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 215), ('new', 182), ('many', 181), ('last', 147), ('former', 117), ('political', 109), ('black', 96), ('such', 89), ('first', 83), ('american', 77)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 457), ('have', 164), ('get', 77), ('do', 75), ('make', 73), ('take', 73), ('go', 52), ('see', 45), ('know', 41), ('help', 38)]\n",
      "\n",
      "1993\n",
      "Most Common Nouns\n",
      "[('war', 293), ('government', 209), ('time', 197), ('city', 174), ('year', 154), ('peace', 154), ('world', 142), ('family', 137), ('country', 128), ('life', 121)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 256), ('many', 247), ('new', 206), ('last', 188), ('american', 152), ('russian', 149), ('political', 129), ('bosnian', 124), ('former', 123), ('first', 119)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 617), ('have', 214), ('do', 126), ('make', 100), ('take', 92), ('get', 90), ('go', 70), ('help', 66), ('see', 65), ('know', 60)]\n",
      "\n",
      "1994\n",
      "Most Common Nouns\n",
      "[('government', 178), ('time', 158), ('war', 148), ('year', 128), ('country', 121), ('town', 110), ('state', 105), ('day', 102), ('percent', 97), ('family', 91)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 208), ('other', 177), ('new', 169), ('last', 132), ('first', 122), ('military', 102), ('political', 94), ('former', 94), ('bosnian', 81), ('such', 78)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 485), ('have', 167), ('go', 86), ('get', 83), ('take', 70), ('do', 58), ('see', 55), ('make', 55), ('help', 47), ('come', 44)]\n",
      "\n",
      "1995\n",
      "Most Common Nouns\n",
      "[('war', 170), ('government', 167), ('world', 159), ('year', 128), ('time', 127), ('peace', 115), ('country', 109), ('percent', 100), ('city', 97), ('state', 84)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 180), ('new', 162), ('many', 149), ('first', 132), ('last', 127), ('bosnian', 125), ('serb', 113), ('former', 95), ('international', 89), ('such', 76)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 484), ('have', 135), ('do', 72), ('take', 64), ('get', 63), ('go', 59), ('make', 55), ('find', 42), ('say', 34), ('help', 33)]\n",
      "\n",
      "1996\n",
      "Most Common Nouns\n",
      "[('year', 158), ('government', 157), ('time', 148), ('percent', 128), ('country', 117), ('war', 110), ('today', 108), ('life', 101), ('day', 100), ('world', 99)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 183), ('first', 171), ('other', 163), ('last', 143), ('many', 126), ('military', 113), ('american', 98), ('former', 97), ('israeli', 92), ('political', 83)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 515), ('have', 180), ('do', 82), ('take', 81), ('help', 64), ('get', 63), ('go', 56), ('make', 54), ('give', 37), ('keep', 37)]\n",
      "\n",
      "1997\n",
      "Most Common Nouns\n",
      "[('government', 182), ('war', 145), ('year', 115), ('percent', 113), ('time', 111), ('country', 91), ('world', 81), ('news', 71), ('money', 70), ('aid', 66)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 159), ('other', 157), ('new', 152), ('last', 106), ('first', 104), ('political', 85), ('former', 74), ('american', 63), ('few', 60), ('such', 59)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 362), ('have', 129), ('do', 62), ('get', 52), ('make', 44), ('take', 41), ('go', 41), ('keep', 31), ('come', 29), ('help', 28)]\n",
      "\n",
      "1998\n",
      "Most Common Nouns\n",
      "[('government', 165), ('time', 136), ('year', 124), ('percent', 117), ('family', 95), ('day', 92), ('week', 85), ('life', 80), ('war', 78), ('country', 77)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 159), ('many', 146), ('last', 130), ('new', 117), ('first', 116), ('israeli', 95), ('palestinian', 73), ('american', 69), ('few', 62), ('former', 58)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 354), ('have', 118), ('do', 58), ('make', 56), ('go', 55), ('get', 53), ('take', 45), ('give', 44), ('help', 41), ('see', 31)]\n",
      "\n",
      "1999\n",
      "Most Common Nouns\n",
      "[('war', 224), ('time', 168), ('family', 130), ('day', 106), ('school', 106), ('year', 104), ('world', 101), ('country', 97), ('way', 86), ('peace', 86)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 203), ('many', 142), ('last', 129), ('new', 128), ('first', 125), ('ethnic', 123), ('american', 100), ('serbian', 91), ('own', 90), ('military', 90)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 495), ('have', 172), ('do', 108), ('get', 78), ('go', 73), ('take', 68), ('see', 60), ('help', 54), ('make', 54), ('know', 47)]\n",
      "\n",
      "2000\n",
      "Most Common Nouns\n",
      "[('government', 164), ('time', 154), ('war', 128), ('family', 124), ('year', 110), ('peace', 109), ('country', 91), ('way', 90), ('state', 87), ('world', 86)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 194), ('many', 161), ('new', 147), ('last', 146), ('israeli', 110), ('palestinian', 110), ('first', 107), ('political', 78), ('few', 76), ('american', 75)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 454), ('have', 136), ('get', 72), ('do', 61), ('go', 58), ('make', 56), ('take', 51), ('come', 42), ('help', 42), ('see', 41)]\n",
      "\n",
      "2001\n",
      "Most Common Nouns\n",
      "[('time', 247), ('world', 211), ('year', 178), ('government', 169), ('country', 156), ('city', 154), ('war', 153), ('day', 151), ('life', 145), ('family', 143)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 257), ('many', 211), ('last', 195), ('new', 194), ('first', 173), ('american', 116), ('good', 105), ('few', 105), ('former', 104), ('islamic', 98)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 686), ('have', 247), ('do', 141), ('get', 128), ('make', 113), ('see', 88), ('take', 88), ('go', 83), ('help', 69), ('find', 58)]\n",
      "\n",
      "2002\n",
      "Most Common Nouns\n",
      "[('director', 343), ('violence', 274), ('staff', 227), ('sexnudity', 194), ('time', 189), ('profanity', 187), ('camp', 163), ('year', 160), ('war', 153), ('government', 153)]\n",
      "\n",
      "Most Common Adj\n",
      "[('israeli', 326), ('palestinian', 236), ('other', 234), ('new', 208), ('many', 198), ('last', 163), ('first', 155), ('young', 111), ('military', 101), ('such', 98)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 514), ('have', 210), ('make', 112), ('do', 100), ('go', 88), ('take', 80), ('get', 72), ('see', 72), ('help', 49), ('find', 44)]\n",
      "\n",
      "2003\n",
      "Most Common Nouns\n",
      "[('director', 311), ('violence', 251), ('war', 234), ('staff', 227), ('sexnudity', 199), ('profanity', 197), ('smoking', 138), ('time', 129), ('day', 123), ('life', 121)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 146), ('other', 140), ('iraqi', 118), ('new', 102), ('first', 99), ('high', 99), ('last', 91), ('young', 86), ('american', 82), ('military', 77)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 377), ('have', 132), ('get', 73), ('go', 70), ('do', 60), ('make', 52), ('take', 47), ('help', 45), ('find', 43), ('know', 42)]\n",
      "\n",
      "2004\n",
      "Most Common Nouns\n",
      "[('director', 319), ('violence', 176), ('time', 147), ('profanity', 127), ('sexnudity', 122), ('family', 119), ('staff', 109), ('world', 108), ('life', 107), ('year', 101)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 138), ('other', 134), ('many', 129), ('palestinian', 117), ('first', 111), ('last', 89), ('american', 77), ('israeli', 76), ('political', 67), ('own', 63)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 349), ('have', 137), ('make', 77), ('do', 70), ('get', 67), ('take', 55), ('see', 50), ('help', 47), ('find', 40), ('know', 38)]\n",
      "\n",
      "2005\n",
      "Most Common Nouns\n",
      "[('director', 205), ('grade', 178), ('family', 130), ('pm', 130), ('time', 125), ('school', 102), ('city', 98), ('government', 96), ('life', 93), ('violence', 86)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 163), ('new', 134), ('many', 127), ('last', 100), ('first', 66), ('few', 61), ('young', 60), ('good', 59), ('local', 57), ('american', 57)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 336), ('have', 134), ('see', 86), ('get', 77), ('make', 59), ('take', 52), ('help', 51), ('go', 49), ('do', 47), ('find', 39)]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "Most Common Nouns\n",
      "[('city', 157), ('time', 146), ('government', 135), ('year', 130), ('family', 125), ('percent', 106), ('war', 105), ('country', 103), ('state', 94), ('market', 92)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 218), ('other', 207), ('new', 177), ('israeli', 149), ('last', 123), ('palestinian', 113), ('first', 111), ('american', 79), ('local', 70), ('international', 70)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 472), ('have', 114), ('do', 89), ('get', 79), ('take', 69), ('go', 69), ('make', 65), ('help', 55), ('see', 45), ('know', 39)]\n",
      "\n",
      "2007\n",
      "Most Common Nouns\n",
      "[('government', 108), ('time', 106), ('year', 98), ('family', 88), ('life', 87), ('city', 83), ('school', 82), ('war', 73), ('world', 71), ('street', 71)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 113), ('many', 98), ('other', 91), ('first', 83), ('last', 72), ('former', 55), ('iraqi', 55), ('political', 53), ('high', 49), ('palestinian', 48)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 335), ('have', 114), ('do', 63), ('get', 63), ('make', 61), ('go', 58), ('take', 36), ('help', 36), ('see', 33), ('find', 32)]\n",
      "\n",
      "2008\n",
      "Most Common Nouns\n",
      "[('time', 87), ('government', 79), ('country', 74), ('year', 68), ('life', 67), ('family', 64), ('war', 57), ('school', 56), ('neighborhood', 48), ('way', 47)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 97), ('other', 88), ('new', 74), ('last', 68), ('first', 50), ('little', 43), ('political', 42), ('few', 40), ('good', 39), ('israeli', 36)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 198), ('have', 68), ('do', 46), ('see', 45), ('go', 41), ('get', 41), ('make', 37), ('take', 32), ('help', 31), ('know', 30)]\n",
      "\n",
      "2009\n",
      "Most Common Nouns\n",
      "[('government', 172), ('war', 101), ('peace', 74), ('city', 65), ('state', 62), ('country', 60), ('time', 58), ('group', 57), ('family', 57), ('year', 56)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 109), ('many', 101), ('israeli', 77), ('new', 74), ('military', 66), ('last', 62), ('such', 52), ('political', 48), ('recent', 46), ('international', 45)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 253), ('have', 81), ('make', 44), ('take', 40), ('get', 37), ('help', 36), ('do', 33), ('go', 31), ('bring', 27), ('see', 25)]\n",
      "\n",
      "2010\n",
      "Most Common Nouns\n",
      "[('country', 118), ('government', 84), ('cream', 67), ('ice', 63), ('time', 60), ('year', 54), ('family', 51), ('city', 49), ('court', 46), ('aid', 45)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 97), ('other', 68), ('new', 52), ('last', 47), ('international', 46), ('american', 45), ('first', 44), ('political', 39), ('ethnic', 38), ('former', 37)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 214), ('have', 68), ('do', 36), ('take', 29), ('see', 26), ('say', 25), ('go', 22), ('get', 21), ('work', 17), ('make', 17)]\n",
      "\n",
      "2011\n",
      "Most Common Nouns\n",
      "[('government', 117), ('country', 75), ('peace', 70), ('war', 70), ('city', 65), ('state', 65), ('world', 62), ('time', 60), ('group', 58), ('food', 58)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 98), ('palestinian', 94), ('many', 87), ('new', 69), ('military', 59), ('syrian', 59), ('israeli', 57), ('last', 52), ('political', 44), ('foreign', 44)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 230), ('have', 57), ('get', 38), ('do', 36), ('go', 30), ('make', 29), ('take', 25), ('work', 25), ('see', 25), ('say', 25)]\n",
      "\n",
      "2012\n",
      "Most Common Nouns\n",
      "[('government', 184), ('country', 94), ('border', 73), ('time', 69), ('sex', 69), ('group', 63), ('trafficking', 61), ('way', 57), ('year', 57), ('violence', 55)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 142), ('other', 115), ('many', 94), ('new', 58), ('last', 57), ('american', 57), ('military', 55), ('first', 50), ('such', 49), ('international', 49)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 253), ('have', 66), ('take', 45), ('get', 44), ('do', 44), ('go', 31), ('help', 30), ('see', 29), ('make', 27), ('leave', 20)]\n",
      "\n",
      "2013\n",
      "Most Common Nouns\n",
      "[('government', 79), ('country', 77), ('time', 76), ('year', 69), ('war', 69), ('percent', 67), ('pm', 56), ('family', 53), ('day', 50), ('life', 49)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 87), ('new', 86), ('other', 72), ('first', 64), ('last', 57), ('such', 51), ('american', 47), ('international', 44), ('syrian', 44), ('political', 41)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 236), ('have', 74), ('get', 38), ('do', 37), ('go', 33), ('help', 28), ('make', 27), ('take', 26), ('see', 23), ('find', 22)]\n",
      "\n",
      "2014\n",
      "Most Common Nouns\n",
      "[('pm', 167), ('year', 113), ('government', 107), ('time', 93), ('family', 91), ('country', 88), ('city', 86), ('school', 82), ('border', 81), ('market', 78)]\n",
      "\n",
      "Most Common Adj\n",
      "[('other', 124), ('many', 119), ('new', 106), ('israeli', 89), ('last', 86), ('first', 80), ('such', 64), ('american', 56), ('local', 47), ('military', 45)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 291), ('have', 106), ('do', 78), ('take', 58), ('go', 54), ('make', 51), ('get', 46), ('help', 40), ('see', 32), ('find', 26)]\n",
      "\n",
      "2015\n",
      "Most Common Nouns\n",
      "[('pm', 294), ('country', 150), ('government', 142), ('family', 130), ('time', 123), ('year', 114), ('state', 105), ('world', 88), ('life', 85), ('part', 82)]\n",
      "\n",
      "Most Common Adj\n",
      "[('many', 165), ('new', 149), ('other', 147), ('political', 95), ('first', 91), ('american', 82), ('last', 80), ('syrian', 70), ('free', 64), ('former', 62)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 339), ('have', 113), ('make', 80), ('take', 64), ('get', 62), ('do', 55), ('go', 50), ('help', 45), ('see', 41), ('give', 37)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre = 'NEWS'\n",
    "genre_years = sorted(data[data['genre']==genre]['year'].unique())\n",
    "get_most_common_POS(data, genre_years, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007\n",
      "Most Common Nouns\n",
      "[('refugee', 533), ('camp', 332), ('army', 47), ('fighting', 35), ('world', 30), ('crisis', 29), ('aid', 24), ('government', 24), ('source', 24), ('return', 24)]\n",
      "\n",
      "Most Common Adj\n",
      "[('iraqi', 176), ('lebanese', 157), ('palestinian', 132), ('new', 32), ('burmese', 23), ('islamist', 21), ('sudanese', 20), ('dead', 20), ('full', 18), ('first', 18)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 49), ('return', 20), ('have', 13), ('take', 12), ('do', 10), ('help', 10), ('start', 9), ('rise', 9), ('get', 9), ('let', 9)]\n",
      "\n",
      "2008\n",
      "Most Common Nouns\n",
      "[('refugee', 1329), ('camp', 330), ('prayer', 98), ('today', 71), ('world', 68), ('day', 61), ('aid', 59), ('news', 55), ('time', 49), ('family', 47)]\n",
      "\n",
      "Most Common Adj\n",
      "[('iraqi', 199), ('new', 97), ('palestinian', 89), ('good', 53), ('first', 41), ('many', 41), ('last', 40), ('great', 38), ('sudanese', 36), ('burmese', 35)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 121), ('rise', 80), ('have', 79), ('help', 65), ('go', 44), ('get', 44), ('take', 42), ('live', 30), ('ve', 29), ('see', 27)]\n",
      "\n",
      "2009\n",
      "Most Common Nouns\n",
      "[('refugee', 2108), ('camp', 414), ('day', 98), ('life', 94), ('status', 91), ('aid', 86), ('today', 79), ('crisis', 79), ('story', 76), ('family', 71)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 164), ('iraqi', 99), ('palestinian', 72), ('first', 57), ('african', 45), ('good', 44), ('somali', 44), ('great', 41), ('former', 41), ('last', 38)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 136), ('help', 101), ('get', 46), ('check', 41), ('see', 37), ('take', 35), ('refugee', 33), ('go', 32), ('have', 31), ('do', 29)]\n",
      "\n",
      "2010\n",
      "Most Common Nouns\n",
      "[('refugee', 1541), ('camp', 323), ('day', 140), ('iranelection', 112), ('today', 97), ('asylum', 95), ('photo', 84), ('story', 82), ('video', 79), ('status', 76)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 153), ('palestinian', 107), ('iraqi', 92), ('iranian', 71), ('somali', 57), ('human', 42), ('many', 42), ('great', 41), ('first', 40), ('haitian', 37)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 126), ('help', 107), ('see', 46), ('get', 42), ('return', 39), ('give', 37), ('go', 34), ('have', 33), ('check', 30), ('refugee', 27)]\n",
      "\n",
      "2011\n",
      "Most Common Nouns\n",
      "[('refugee', 1195), ('camp', 480), ('day', 144), ('border', 109), ('today', 108), ('amp', 103), ('photo', 95), ('aid', 90), ('crisis', 87), ('video', 86)]\n",
      "\n",
      "Most Common Adj\n",
      "[('new', 158), ('palestinian', 138), ('somali', 120), ('libyan', 93), ('syrian', 87), ('african', 47), ('many', 45), ('humanitarian', 42), ('tunisian', 42), ('iraqi', 35)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 153), ('help', 117), ('get', 43), ('see', 42), ('have', 39), ('stop', 36), ('do', 35), ('check', 33), ('return', 32), ('know', 31)]\n",
      "\n",
      "2012\n",
      "Most Common Nouns\n",
      "[('refugee', 1254), ('camp', 432), ('amp', 116), ('day', 103), ('today', 101), ('crisis', 85), ('health', 84), ('story', 81), ('border', 81), ('photo', 79)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 361), ('new', 131), ('palestinian', 131), ('african', 76), ('many', 53), ('jewish', 48), ('great', 48), ('somali', 44), ('israeli', 40), ('first', 40)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 188), ('help', 91), ('refugee', 47), ('have', 41), ('see', 40), ('do', 39), ('ve', 36), ('know', 35), ('go', 35), ('take', 34)]\n",
      "\n",
      "2013\n",
      "Most Common Nouns\n",
      "[('refugee', 1079), ('camp', 371), ('asylum', 121), ('crisis', 114), ('amp', 113), ('day', 107), ('today', 99), ('aid', 95), ('story', 84), ('world', 82)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 794), ('new', 135), ('palestinian', 96), ('last', 54), ('young', 52), ('humanitarian', 51), ('many', 51), ('first', 51), ('great', 44), ('other', 42)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 201), ('help', 141), ('see', 49), ('go', 47), ('take', 42), ('stop', 40), ('watch', 39), ('know', 39), ('have', 38), ('get', 38)]\n",
      "\n",
      "2014\n",
      "Most Common Nouns\n",
      "[('refugee', 950), ('camp', 317), ('day', 128), ('amp', 115), ('today', 105), ('asylum', 103), ('photo', 102), ('child', 100), ('family', 92), ('crisis', 91)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 497), ('new', 116), ('many', 78), ('palestinian', 73), ('old', 61), ('humanitarian', 52), ('african', 51), ('young', 41), ('iraqi', 40), ('dead', 39)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 187), ('help', 102), ('get', 46), ('ve', 45), ('see', 41), ('do', 41), ('have', 39), ('stop', 36), ('take', 35), ('go', 33)]\n",
      "\n",
      "2015\n",
      "Most Common Nouns\n",
      "[('refugee', 928), ('camp', 223), ('crisis', 201), ('today', 101), ('amp', 100), ('life', 95), ('family', 76), ('world', 68), ('isis', 63), ('story', 60)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 582), ('new', 113), ('palestinian', 54), ('many', 53), ('safe', 47), ('young', 43), ('auspol', 40), ('muslim', 39), ('other', 38), ('last', 38)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 173), ('help', 105), ('take', 74), ('have', 48), ('get', 45), ('do', 42), ('stop', 37), ('go', 35), ('see', 34), ('make', 30)]\n",
      "\n",
      "2016\n",
      "Most Common Nouns\n",
      "[('refugee', 987), ('crisis', 152), ('camp', 127), ('amp', 100), ('world', 96), ('child', 94), ('today', 77), ('year', 71), ('country', 67), ('family', 65)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 549), ('muslim', 98), ('new', 85), ('german', 58), ('many', 58), ('first', 54), ('young', 35), ('safe', 34), ('good', 32), ('own', 32)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 226), ('help', 105), ('take', 81), ('do', 55), ('have', 45), ('get', 44), ('stop', 42), ('bring', 38), ('go', 37), ('keep', 32)]\n",
      "\n",
      "2017\n",
      "Most Common Nouns\n",
      "[('refugee', 1097), ('crisis', 153), ('amp', 141), ('camp', 104), ('rohingya', 102), ('world', 98), ('trump', 85), ('country', 83), ('child', 80), ('family', 78)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 251), ('new', 129), ('many', 89), ('muslim', 88), ('good', 59), ('last', 57), ('manus', 53), ('other', 45), ('first', 44), ('safe', 41)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 241), ('help', 109), ('take', 68), ('get', 53), ('have', 52), ('go', 52), ('do', 49), ('ve', 46), ('stop', 45), ('see', 42)]\n",
      "\n",
      "2018\n",
      "Most Common Nouns\n",
      "[('refugee', 1379), ('amp', 237), ('country', 200), ('asylum', 177), ('camp', 175), ('world', 160), ('crisis', 144), ('today', 142), ('year', 133), ('rohingya', 132)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 236), ('new', 138), ('many', 133), ('last', 99), ('palestinian', 97), ('other', 96), ('first', 93), ('human', 79), ('safe', 70), ('muslim', 65)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 469), ('help', 129), ('have', 103), ('do', 102), ('take', 95), ('get', 89), ('make', 68), ('go', 66), ('see', 60), ('stop', 50)]\n",
      "\n",
      "2019\n",
      "Most Common Nouns\n",
      "[('refugee', 1299), ('amp', 282), ('country', 258), ('asylum', 237), ('today', 186), ('family', 176), ('camp', 163), ('government', 147), ('world', 147), ('crisis', 139)]\n",
      "\n",
      "Most Common Adj\n",
      "[('syrian', 189), ('new', 147), ('many', 146), ('human', 126), ('other', 121), ('first', 95), ('last', 92), ('own', 84), ('safe', 76), ('medical', 76)]\n",
      "\n",
      "Most Common Verbs\n",
      "[('be', 560), ('have', 144), ('do', 126), ('help', 121), ('get', 109), ('make', 92), ('take', 92), ('go', 82), ('see', 70), ('stop', 63)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genre = 'twitter'\n",
    "genre_years = sorted(data[data['genre']==genre]['year'].unique())\n",
    "get_most_common_POS(data, genre_years, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Word Cloud by year and genre\n",
    "for yr in years:\n",
    "    for g in genres:\n",
    "        yearly = data[(data[\"genre\"]==g) & (data['year']==yr)]\n",
    "        words = yearly['normalized_words'].sum()\n",
    "        if words==0:\n",
    "            continue\n",
    "        wc = wordcloud.WordCloud(background_color=\"white\", max_words=500, width= 1000, height = 1000, mode ='RGBA', scale=.5).generate(' '.join(words))\n",
    "        wc.to_file('wordcloud/data_{}_{}.png'.format(yr, g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud by year\n",
    "for yr in years:\n",
    "    yearly = data[data['year']==yr]\n",
    "    words = yearly['normalized_words'].sum()\n",
    "    if words==0:\n",
    "        continue\n",
    "    wc = wordcloud.WordCloud(background_color=\"white\", max_words=500, width= 1000, height = 1000, mode ='RGBA', scale=.5).generate(' '.join(words))\n",
    "    wc.to_file('wordcloud/data_{}_All.png'.format(yr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1990\n",
      "[(('unite', 'state'), 7242.095258047035), (('saddam', 'hussein'), 5070.514935596461), (('saudi', 'arabia'), 4574.108121239991), (('soviet', 'union'), 3964.4579606316947), (('khmer', 'rouge'), 3273.287562752811)]\n",
      "[(('unite', 'state', 'baker'), 11150.260910882527), (('ambassador', 'unite', 'state'), 11130.192965367232), (('unite', 'state', 'soviet'), 10953.49391724261), (('unite', 'state', 'government'), 10935.590402072667), (('unite', 'state', 's'), 10925.819747032008)]\n",
      "1991\n",
      "[(('unite', 'state'), 8661.412428533353), (('saddam', 'hussein'), 7471.140858812556), (('soviet', 'union'), 4166.009223228741), (('new', 'york'), 3348.505297479314), (('abc', 'news'), 3267.0554730484187)]\n",
      "[(('unite', 'state', 'baker'), 13268.918637990577), (('president', 'unite', 'state'), 13155.42015349009), (('unite', 'state', 'america'), 13075.725771298034), (('unite', 'state', 'israel'), 13070.265422139604), (('ambassador', 'unite', 'state'), 13068.338935056696)]\n",
      "1992\n",
      "[(('unite', 'state'), 4059.4123460297988), (('new', 'york'), 2561.507826961821), (('peter', 'jennings'), 2232.5706336165786), (('unite', 'nation'), 1968.4952420988916), (('abc', 'news'), 1745.953714051516)]\n",
      "[(('vatican', 'unite', 'state'), 6187.776349686257), (('president', 'unite', 'state'), 6154.478192059163), (('unite', 'state', 'america'), 6150.756223071309), (('asylum', 'unite', 'state'), 6148.117006457858), (('japan', 'unite', 'state'), 6137.318527977444)]\n",
      "1993\n",
      "[(('unite', 'state'), 4304.532338809), (('new', 'york'), 3084.6444552847197), (('unite', 'nation'), 2338.1493308092117), (('health', 'care'), 1975.3530954904668), (('los', 'angeles'), 1731.8072058391385)]\n",
      "[(('unite', 'state', 'official'), 6626.689481707757), (('unite', 'state', 'america'), 6527.70861595822), (('president', 'unite', 'state'), 6519.504723672081), (('unite', 'state', 'government'), 6517.199744576881), (('county', 'unite', 'state'), 6516.361131424913)]\n",
      "1994\n",
      "[(('unite', 'state'), 7103.977293233494), (('sam', 'donaldson'), 6408.959860280823), (('david', 'brinkley'), 5670.356986741632), (('health', 'care'), 4490.982491170516), (('cokie', 'roberts'), 3944.6537221088124)]\n",
      "[(('unite', 'state', 'department'), 11375.163907693714), (('come', 'unite', 'state'), 10770.580227813876), (('organization', 'unite', 'state'), 10764.8300581371), (('president', 'unite', 'state'), 10753.817158676111), (('ambassador', 'unite', 'state'), 10734.388482601635)]\n",
      "1995\n",
      "[(('ted', 'koppel'), 3510.3943321408215), (('unite', 'nation'), 2594.2412784527296), (('unite', 'state'), 2361.3677182215006), (('new', 'york'), 2082.7805624816897), (('cokie', 'roberts'), 1757.7388557610452)]\n",
      "[(('ted', 'koppel', 'let'), 5521.475120486995), (('ted', 'koppel', 'voiceover'), 5411.830960382042), (('ted', 'koppel', 'mr'), 5365.580606599057), (('break', 'ted', 'koppel'), 5353.757392081926), (('yes', 'ted', 'koppel'), 5333.223085509811)]\n",
      "1996\n",
      "[(('dept', 'fs'), 4286.105170900355), (('unite', 'state'), 3528.5927619010463), (('cokie', 'roberts'), 2728.396089570979), (('sam', 'donaldson'), 2452.003522116282), (('new', 'york'), 2174.2888791693367)]\n",
      "[(('nf', 'dept', 'fs'), 8491.185857790682), (('nwr', 'dept', 'fs'), 7861.530106171758), (('dept', 'fs', 'box'), 7708.424856428517), (('np', 'dept', 'fs'), 7011.31520216798), (('dept', 'fs', 'rt'), 6872.050527482534)]\n",
      "1997\n",
      "[(('unite', 'state'), 2357.8865105230375), (('hong', 'kong'), 1683.7641247821773), (('new', 'york'), 1186.459472878799), (('prime', 'minister'), 895.8536853245424), (('san', 'francisco'), 859.554754959864)]\n",
      "[(('unite', 'state', 'department'), 3762.7600137606464), (('ambassador', 'unite', 'state'), 3594.035605481831), (('unite', 'state', 'albright'), 3589.4871705749424), (('come', 'unite', 'state'), 3586.751725255927), (('unite', 'state', 'attorney'), 3577.979360428487)]\n",
      "1998\n",
      "[(('unite', 'state'), 2246.7851219772483), (('barbara', 'walters'), 2026.7451971775467), (('new', 'york'), 1748.5270026153948), (('kevin', 'newman'), 1322.1566200369007), (('white', 'house'), 1078.7884564103058)]\n",
      "[(('barbara', 'walters', 'voiceover'), 3528.6485489363367), (('counterpart', 'unite', 'state'), 3405.181867696199), (('immigrate', 'unite', 'state'), 3404.5047791924253), (('switzerland', 'unite', 'state'), 3404.5047791924253), (('president', 'unite', 'state'), 3402.3964444825)]\n",
      "1999\n",
      "[(('unite', 'state'), 4340.636537038103), (('peter', 'jennings'), 3375.488931897187), (('new', 'york'), 3239.5389598498286), (('white', 'house'), 1518.1675157224113), (('grind', 'troop'), 1370.1556908748)]\n",
      "[(('president', 'unite', 'state'), 6703.578555074208), (('unite', 'state', 'senate'), 6589.786363800838), (('unite', 'state', 'nato'), 6585.747108284502), (('unite', 'state', 'jimmy'), 6567.32113546566), (('unite', 'state', 'britain'), 6561.286368999073)]\n",
      "2000\n",
      "[(('unite', 'state'), 2409.9039290014457), (('video', 'clip'), 1986.8887322437834), (('new', 'york'), 1657.0323136632237), (('prime', 'minister'), 1362.01608296884), (('human', 'right'), 1026.7933843096544)]\n",
      "[(('begin', 'video', 'clip'), 3900.1877750094773), (('end', 'video', 'clip'), 3867.4812458505553), (('unite', 'state', 'high'), 3675.1317686343737), (('unite', 'state', 'israel'), 3668.6825472170713), (('cnn', 'unite', 'state'), 3665.9470016834107)]\n",
      "2001\n",
      "[(('unite', 'state'), 3890.9776800140758), (('bin', 'lade'), 3582.354415761099), (('new', 'york'), 3003.636580950404), (('northern', 'alliance'), 2048.7471243794907), (('osama', 'bin'), 1358.1469397974083)]\n",
      "[(('osama', 'bin', 'lade'), 7410.7968440850545), (('unite', 'state', 'america'), 5903.162664148554), (('attack', 'unite', 'state'), 5893.4056655531995), (('ambassador', 'unite', 'state'), 5878.095022797234), (('nation', 'unite', 'state'), 5876.0703639066105)]\n",
      "2002\n",
      "[(('unite', 'state'), 3608.0797777726975), (('west', 'bank'), 2857.139570114422), (('min', 'sterritt'), 2528.704245347547), (('middle', 'east'), 2268.4011587757723), (('new', 'york'), 2241.9412846749574)]\n",
      "[(('unite', 'state', 'israel'), 5511.575369270762), (('president', 'unite', 'state'), 5485.249461712516), (('asset', 'unite', 'state'), 5449.461276619021), (('state', 'unite', 'state'), 5448.602074523159), (('unite', 'state', 'diffuse'), 5440.87345888232)]\n",
      "2003\n",
      "[(('unite', 'state'), 3374.068163224565), (('min', 'sterritt'), 2998.398484533872), (('new', 'york'), 1821.7036599208323), (('photo', 'color'), 1737.525114618673), (('saddam', 'hussein'), 1697.0745079563178)]\n",
      "[(('ambassador', 'unite', 'state'), 5113.037737138335), (('unite', 'state', 'australia'), 5105.274732926159), (('president', 'unite', 'state'), 5104.606263746371), (('unite', 'state', 'britain'), 5101.698156349231), (('unite', 'state', 'democracy'), 5100.8769649389415)]\n",
      "2004\n",
      "[(('min', 'sterritt'), 3633.9513128259005), (('unite', 'state'), 1959.2292369584097), (('new', 'york'), 1428.3615244189252), (('unidentified', 'male'), 1136.891977189853), (('rate', 'director'), 1119.7190305230693)]\n",
      "[(('min', 'sterritt', 'documentary'), 5870.957814336514), (('min', 'sterritt', 'young'), 5550.459839273086), (('min', 'sterritt', 'remake'), 5524.044159776491), (('min', 'sterritt', 'fictionalize'), 5520.059339993428), (('moore', 'min', 'sterritt'), 5502.491356394998)]\n",
      "2005\n",
      "[(('new', 'orleans'), 3370.6771358458072), (('unite', 'state'), 2456.422177840922), (('kotb', 'voiceover'), 1963.2444273292776), (('new', 'york'), 1718.3372642458157), (('video', 'clip'), 1483.8974193136223)]\n",
      "[(('mayor', 'new', 'orleans'), 5240.862145716916), (('city', 'new', 'orleans'), 5220.688229060165), (('new', 'orleans', 'time'), 5178.62716623597), (('new', 'orleans', 'city'), 5153.045149056266), (('new', 'orleans', 'louisiana'), 5131.248841966074)]\n",
      "2006\n",
      "[(('unite', 'state'), 3312.6992791630323), (('north', 'korea'), 2888.027121216335), (('san', 'francisco'), 2349.2164840210585), (('new', 'orleans'), 1811.1331563505942), (('new', 'york'), 1799.2301763033036)]\n",
      "[(('unite', 'state', 'condoleezza'), 5248.188774377648), (('unite', 'state', 'department'), 5232.130414936468), (('ambassador', 'unite', 'state'), 5071.887306930543), (('president', 'unite', 'state'), 5017.278441929388), (('unite', 'state', 'europe'), 5009.346054033432)]\n",
      "2007\n",
      "[(('refugee', 'camp'), 3378.5948708548194), (('unite', 'state'), 2181.618550906789), (('new', 'york'), 1317.8500131230394), (('iraqi', 'refugee'), 1209.437698789835), (('palestinian', 'refugee'), 958.6385593646874)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('palestinian', 'refugee', 'camp'), 6608.448595311322), (('baqaa', 'refugee', 'camp'), 5474.888894323913), (('lebanon', 'refugee', 'camp'), 5451.593823284869), (('refugee', 'camp', 'lebanon'), 5381.115812869053), (('darfur', 'refugee', 'camp'), 5353.177858355824)]\n",
      "2008\n",
      "[(('refugee', 'camp'), 2710.016426403935), (('new', 'york'), 1285.9014996254236), (('unite', 'state'), 1281.1309966560802), (('iraqi', 'refugee'), 1125.7584002352075), (('wwwnewestdiscoverycom', 'update'), 959.7331460128814)]\n",
      "[(('palestinian', 'refugee', 'camp'), 4842.11727337456), (('darfur', 'refugee', 'camp'), 4462.858540354538), (('un', 'refugee', 'camp'), 4415.882287727687), (('tibetan', 'refugee', 'camp'), 4408.143960835227), (('like', 'refugee', 'camp'), 4347.724445344288)]\n",
      "2009\n",
      "[(('refugee', 'camp'), 4192.072205268116), (('mankiewicz', 'voiceover'), 1376.6589954880797), (('sri', 'lanka'), 1270.346183714314), (('unite', 'state'), 1236.2636997923817), (('unite', 'nation'), 976.6402083252387)]\n",
      "[(('iraqi', 'refugee', 'camp'), 7173.898967861078), (('un', 'refugee', 'camp'), 7057.133313025204), (('palestinian', 'refugee', 'camp'), 6792.807661965824), (('somali', 'refugee', 'camp'), 6521.80467831336), (('climate', 'refugee', 'camp'), 6503.290005085264)]\n",
      "2010\n",
      "[(('refugee', 'camp'), 3107.3547707471407), (('new', 'york'), 1351.2392387880157), (('unite', 'state'), 1207.5689068700624), (('ice', 'cream'), 1163.182212988258), (('htan', 'dah'), 721.7832549577635)]\n",
      "[(('palestinian', 'refugee', 'camp'), 5574.992639023207), (('un', 'refugee', 'camp'), 5257.90731796253), (('somali', 'refugee', 'camp'), 5094.5778981233125), (('world', 'refugee', 'camp'), 4947.9123631822), (('burmese', 'refugee', 'camp'), 4877.680675871775)]\n",
      "2011\n",
      "[(('refugee', 'camp'), 4832.521946508624), (('unite', 'state'), 1489.7975281097), (('bin', 'lade'), 897.2041979913004), (('new', 'york'), 855.33468681658), (('year', 'ago'), 709.7039882959439)]\n",
      "[(('dadaab', 'refugee', 'camp'), 8638.495866443554), (('palestinian', 'refugee', 'camp'), 8227.487649354209), (('somali', 'refugee', 'camp'), 8161.979341196478), (('refugee', 'camp', 'kenya'), 7793.424853432429), (('large', 'refugee', 'camp'), 7706.162594321097)]\n",
      "2012\n",
      "[(('refugee', 'camp'), 4386.293114438026), (('syrian', 'refugee'), 1984.275404141623), (('mitt', 'romney'), 1468.0703091907371), (('unite', 'state'), 1452.692698679544), (('new', 'york'), 1122.9803322027374)]\n",
      "[(('syrian', 'refugee', 'camp'), 9564.660954876872), (('palestinian', 'refugee', 'camp'), 7733.341745994641), (('refugee', 'camp', 'jordan'), 6893.722719109199), (('yida', 'refugee', 'camp'), 6892.337274244687), (('un', 'refugee', 'camp'), 6858.721763493079)]\n",
      "2013\n",
      "[(('syrian', 'refugee'), 5042.463335683141), (('refugee', 'camp'), 3621.8280196574988), (('unite', 'state'), 2917.123140242141), (('chemical', 'weapon'), 2011.14004485313), (('new', 'york'), 1481.9932333095164)]\n",
      "[(('syrian', 'refugee', 'camp'), 13038.514296203908), (('syrian', 'refugee', 'crisis'), 8228.58662869925), (('syrian', 'refugee', 'child'), 8052.6427874771425), (('syrian', 'refugee', 'flee'), 7944.772653025713), (('syrian', 'refugee', 'syria'), 7783.223190587885)]\n",
      "2014\n",
      "[(('unite', 'state'), 4060.101876194808), (('syrian', 'refugee'), 3286.039234518822), (('refugee', 'camp'), 3241.217111558217), (('white', 'house'), 2085.1909096186305), (('president', 'obama'), 1729.2049400607773)]\n",
      "[(('syrian', 'refugee', 'camp'), 9803.388882784475), (('ambassador', 'unite', 'state'), 6193.393749829182), (('unite', 'state', 'america'), 6191.880630671452), (('president', 'unite', 'state'), 6182.9855083691855), (('unite', 'state', 'iraq'), 6168.982187726455)]\n",
      "2015\n",
      "[(('syrian', 'refugee'), 5299.884394028429), (('unite', 'state'), 4016.931801710012), (('donald', 'trump'), 3594.4009068323394), (('refugee', 'camp'), 2073.1063150796735), (('middle', 'east'), 2006.5567913790205)]\n",
      "[(('syrian', 'refugee', 'camp'), 11105.89976090155), (('syrian', 'refugee', 'crisis'), 10080.051459183349), (('syrian', 'refugee', 'child'), 8375.119870443817), (('syrian', 'refugee', 'arrive'), 8228.560996186054), (('syrian', 'refugee', 'girl'), 8179.220933844779)]\n",
      "2016\n",
      "[(('syrian', 'refugee'), 2506.367548549186), (('refugee', 'refugee'), 578.829124409289), (('refugee', 'camp'), 526.4094750269365), (('refugee', 'crisis'), 514.3938813834138), (('donald', 'trump'), 340.8272443395856)]\n",
      "[(('syrian', 'refugee', 'refugee'), 4666.816144053477), (('syrian', 'refugee', 'camp'), 4578.40304470568), (('syrian', 'refugee', 'crisis'), 4560.51680320975), (('refugee', 'syrian', 'refugee'), 4256.5518334587105), (('syrian', 'refugee', 'child'), 3951.5282328273206)]\n",
      "2017\n",
      "[(('syrian', 'refugee'), 1010.1792811491957), (('refugee', 'refugee'), 472.9112072172908), (('refugee', 'crisis'), 442.7964906644081), (('travel', 'ban'), 428.60519143291856), (('refugee', 'camp'), 427.9436085192975)]\n",
      "[(('syrian', 'refugee', 'crisis'), 2189.419521038423), (('syrian', 'refugee', 'camp'), 2167.687721163429), (('refugee', 'syrian', 'refugee'), 1961.1796260763717), (('refugee', 'refugee', 'refugee'), 1928.3386912351575), (('syrian', 'refugee', 'child'), 1765.745864404917)]\n",
      "2018\n",
      "[(('asylum', 'seeker'), 974.4380220361419), (('syrian', 'refugee'), 898.0167511462096), (('refugee', 'camp'), 840.8984664834327), (('don', 't'), 604.6886438992855), (('rohingya', 'refugee'), 504.6446904317958)]\n",
      "[(('syrian', 'refugee', 'camp'), 2610.560127939206), (('rohingya', 'refugee', 'camp'), 2035.8008728348188), (('syrian', 'refugee', 'refugee'), 1910.7274246662942), (('syrian', 'refugee', 'crisis'), 1842.2938560621026), (('palestinian', 'refugee', 'camp'), 1791.7024205170321)]\n",
      "2019\n",
      "[(('asylum', 'seeker'), 1353.3148751129336), (('don', 't'), 999.3764831784586), (('syrian', 'refugee'), 759.0095142134351), (('refugee', 'camp'), 756.0582759913227), (('human', 'right'), 728.4870285252465)]\n",
      "[(('syrian', 'refugee', 'camp'), 2273.1240653685963), (('refugee', 'asylum', 'seeker'), 2148.4059825055674), (('amp', 'asylum', 'seeker'), 2109.2472651823414), (('asylum', 'seeker', 'human'), 2090.8795494476735), (('asylum', 'seeker', 'arrive'), 2065.1224058349426)]\n"
     ]
    }
   ],
   "source": [
    "# collocations\n",
    "for yr in years:\n",
    "    yearly = data[data['year']==yr]\n",
    "    words = yearly['normalized_words'].sum()\n",
    "    \n",
    "    data_bigrams = nltk.collocations.BigramCollocationFinder.from_words(words)\n",
    "    bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    print(yr)\n",
    "    print(data_bigrams.score_ngrams(bigram_measures.likelihood_ratio)[:5])\n",
    "    \n",
    "    data_trigrams = nltk.collocations.TrigramCollocationFinder.from_words(words)\n",
    "    trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "    print(data_trigrams.score_ngrams(trigram_measures.likelihood_ratio)[:5])\n",
    "    \n",
    "# other options include student_t, chi_sq, likelihood_ratio, pmi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(X, Y):\n",
    "    P = X.copy()\n",
    "    Q = Y.copy()\n",
    "    P.columns = ['P']\n",
    "    Q.columns = ['Q']\n",
    "    df = Q.join(P).fillna(0)\n",
    "    p = df.iloc[:,1]\n",
    "    q = df.iloc[:,0]\n",
    "    D_kl = scipy.stats.entropy(p, q)\n",
    "    return D_kl\n",
    "\n",
    "def chi2_divergence(X,Y):\n",
    "    P = X.copy()\n",
    "    Q = Y.copy()\n",
    "    P.columns = ['P']\n",
    "    Q.columns = ['Q']\n",
    "    df = Q.join(P).fillna(0)\n",
    "    p = df.iloc[:,1]\n",
    "    q = df.iloc[:,0]\n",
    "    return scipy.stats.chisquare(p, q).statistic\n",
    "\n",
    "def Divergence(corpus1, corpus2, difference=\"KL\"):\n",
    "    \"\"\"Difference parameter can equal KL, Chi2, or Wass\"\"\"\n",
    "    freqP = nltk.FreqDist(corpus1)\n",
    "    P = pd.DataFrame(list(freqP.values()), columns = ['frequency'], index = list(freqP.keys()))\n",
    "    freqQ = nltk.FreqDist(corpus2)\n",
    "    Q = pd.DataFrame(list(freqQ.values()), columns = ['frequency'], index = list(freqQ.keys()))\n",
    "    if difference == \"KL\":\n",
    "        return kl_divergence(P, Q)\n",
    "    elif difference == \"Chi2\":\n",
    "        return chi2_divergence(P, Q)\n",
    "    elif difference == \"KS\":\n",
    "        try:\n",
    "            return scipy.stats.ks_2samp(P['frequency'], Q['frequency']).statistic\n",
    "        except:\n",
    "            return scipy.stats.ks_2samp(P['frequency'], Q['frequency'])\n",
    "    elif difference == \"Wasserstein\":\n",
    "        try:\n",
    "            return scipy.stats.wasserstein_distance(P['frequency'], Q['frequency'], u_weights=None, v_weights=None).statistic\n",
    "        except:\n",
    "            return scipy.stats.wasserstein_distance(P['frequency'], Q['frequency'], u_weights=None, v_weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_div_heatmap(corpora, fileids, diff_measure='KL'):\n",
    "    '''\n",
    "    Diff measure = KL, Chi2, KS or Wasserstein\n",
    "    '''\n",
    "    L = []\n",
    "    for p in corpora:\n",
    "        l = []\n",
    "        for q in corpora:\n",
    "            l.append(Divergence(p,q, difference = diff_measure))\n",
    "        L.append(l)\n",
    "    M = np.array(L)\n",
    "    fig = plt.figure()\n",
    "    div = pd.DataFrame(M, columns = fileids, index = fileids)\n",
    "    ax = sns.heatmap(div)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO CHECK\n",
    "corpora = data['normalized_words'][:2].sum()\n",
    "# corpora = []\n",
    "# for index, row in data.iterrows():\n",
    "#     corpora.append(row['tokenized_words'])\n",
    "fileids = list(data['text_id'][:2])\n",
    "plot_div_heatmap(corpora, fileids,diff_measure='KL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCooccurrence(sentences, makeMatrix = False):\n",
    "    words = set()\n",
    "    for sent in sentences:\n",
    "        words |= set(sent)\n",
    "    wordLst = list(words)\n",
    "    wordIndices = {w: i for i, w in enumerate(wordLst)}\n",
    "    wordCoCounts = {}\n",
    "    #consider a sparse matrix if memory becomes an issue\n",
    "    coOcMat = np.zeros((len(wordIndices), len(wordIndices)))\n",
    "    for sent in sentences:\n",
    "        for i, word1 in enumerate(sent):\n",
    "            word1Index = wordIndices[word1]\n",
    "            for word2 in sent[i + 1:]:\n",
    "                coOcMat[word1Index][wordIndices[word2]] += 1\n",
    "    if makeMatrix:\n",
    "        return coOcMat, wordLst\n",
    "    else:\n",
    "        coOcMat = coOcMat.T + coOcMat\n",
    "        g = nx.convert_matrix.from_numpy_matrix(coOcMat)\n",
    "        g = nx.relabel_nodes(g, {i : w for i, w in enumerate(wordLst)})\n",
    "        return g\n",
    "\n",
    "def connected_component_subgraphs(G):\n",
    "    for c in nx.connected_components(G):\n",
    "        yield G.subgraph(c)\n",
    "\n",
    "def posCooccurrence(sentences, *posType, makeMatrix = False):\n",
    "    words = set()\n",
    "    reducedSents = []\n",
    "    #Only using the first kind of POS for each word\n",
    "    wordsMap = {}\n",
    "    for sent in sentences:\n",
    "        s = [(w, t) for w, t in lucem_illud_2020.spacy_pos(sent) if t in posType]\n",
    "        for w, t in s:\n",
    "            if w not in wordsMap:\n",
    "                wordsMap[w] = t\n",
    "        reducedSent = [w for w, t in s]\n",
    "        words |= set(reducedSent)\n",
    "        reducedSents.append(reducedSent)\n",
    "    wordLst = list(words)\n",
    "    wordIndices = {w: i for i, w in enumerate(wordLst)}\n",
    "    wordCoCounts = {}\n",
    "    #consider a sparse matrix if memory becomes an issue\n",
    "    coOcMat = np.zeros((len(wordIndices), len(wordIndices)))\n",
    "    for sent in reducedSents:\n",
    "        for i, word1 in enumerate(sent):\n",
    "            word1Index = wordIndices[word1]\n",
    "            for word2 in sent[i + 1:]:\n",
    "                coOcMat[word1Index][wordIndices[word2]] += 1\n",
    "    if makeMatrix:\n",
    "        return coOcMat, wordLst\n",
    "    else:\n",
    "        coOcMat = coOcMat.T + coOcMat\n",
    "        g = nx.convert_matrix.from_numpy_matrix(coOcMat)\n",
    "        g = nx.relabel_nodes(g, {i : w for i, w in enumerate(wordLst)})\n",
    "        for w in g.nodes:\n",
    "            g.nodes[w]['bipartite'] = wordsMap[w]\n",
    "        return g\n",
    "\n",
    "def plot_word_graph(graph):\n",
    "    layout = nx.spring_layout(graph, weight='weight', iterations= 100)\n",
    "    fig, ax = plt.subplots(figsize = (10,10))\n",
    "    nx.draw(graph, ax = ax, pos = layout, labels = {n:n for n in graph.nodes()},\n",
    "            width=.2, \n",
    "            alpha = .9, \n",
    "            node_size = 100,\n",
    "            node_color = \"xkcd:light red\",\n",
    "            edge_color='xkcd:black')\n",
    "\n",
    "def plot_word_centrality(g):\n",
    "    layout_nn = nx.spring_layout(g, weight='weight', iterations= 100)\n",
    "    fig, ax = plt.subplots(figsize = (10,10))\n",
    "    centralities_nn = nx.eigenvector_centrality(g)\n",
    "    maxC = max(centralities_nn.items(), key = lambda x : x[1])[1]\n",
    "    #maxWeight = max((d['weight'] for n1, n2, d in g.edges(data = True)))\n",
    "    #minWeight = min((d['weight'] for n1, n2, d in g.edges(data = True)))\n",
    "    nx.draw(g, ax = ax, pos = layout_nn, labels = {n: n for n in g.nodes()},\n",
    "            #width=[(d['weight'] - minWeight + .7) / maxWeight for n1, n2, d in gNN.edges(data = True)], \n",
    "            alpha = .9, \n",
    "            node_color = [centralities_nn[n] / maxC for n in g.nodes],\n",
    "            node_size = [centralities_nn[n] / maxC * 100 for n in g.nodes],\n",
    "            font_size = 16,\n",
    "            font_color = 'xkcd:dark grey',\n",
    "            edge_color = 'xkcd:medium blue',\n",
    "            cmap = plt.get_cmap('plasma'),\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot word network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot word network\n",
    "g = wordCooccurrence(data['normalized_sents'].sum())\n",
    "len(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_choice = 25\n",
    "# remove if less than 25\n",
    "g.remove_edges_from([(n1, n2) for n1, n2, d in g.edges(data = True) if d['weight'] <= weight_choice])\n",
    "#since we are changing the graph list() evaluates the isolates first\n",
    "g.remove_nodes_from(list(nx.isolates(g)))\n",
    "# keep just the giant connected component\n",
    "main_graph = max(connected_component_subgraphs(g), key=len)\n",
    "print(nx.info(main_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_word_graph(main_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sub-graph\n",
    "immigrant_neighbors = main_graph.neighbors('family')\n",
    "subgraph_immigrant = main_graph.subgraph(immigrant_neighbors)\n",
    "print(nx.info(subgraph_immigrant))\n",
    "\n",
    "plot_word_graph(subgraph_immigrant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cliques\n",
    "print(', '.join(max(nx.clique.find_cliques(main_graph), key = lambda x: len(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot word network by pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot pos network\n",
    "gNV = posCooccurrence(data['normalized_sents'].sum(), 'NN', 'VB')\n",
    "print(nx.info(gNV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_threshold= 100\n",
    "weight_threshold = 2\n",
    "gNV.remove_nodes_from([n for n in gNV.nodes if len(set(gNV.neighbors(n))) <= degree_threshold]) \n",
    "print(nx.info(gNV))\n",
    "gNV.remove_edges_from([(n1, n2) for n1, n2, d in gNV.edges(data = True) if d['weight'] <= weight_threshold])\n",
    "print(nx.info(gNV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO CHECK\n",
    "plot_word_centrality(gNV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw egocentric network\n",
    "g_immigrant_NV = gNV.subgraph(['family'] + list(gNV.neighbors('family')))\n",
    "print(nx.info(g_immigrant_NV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(g_immigrant_NV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### centrality & global measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#centralities\n",
    "\n",
    "centralities = nx.degree_centrality(main_graph)\n",
    "#centralities = nx.eigenvector_centrality(main_graph)\n",
    "#centralities = nx.closeness_centrality(main_graph)\n",
    "#centralities = nx.betweenness.betweenness_centrality(main_graph)\n",
    "plt.hist(list(centralities.values()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'degree'\n",
    "\n",
    "centrality_df = pandas.DataFrame.from_dict(centralities, orient='index', columns=[name])\n",
    "centrality_df.sort_values(by=name, ascending=False, inplace=True)\n",
    "#highest 10\n",
    "centrality_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global measures\n",
    "density = nx.density(main_graph)\n",
    "mean_degree_pernode = np.mean([v for w,v in nx.degree(main_graph)])\n",
    "diameter = nx.diameter(main_graph)\n",
    "print(\n",
    "\"The density of this graph is {}\\n\\\n",
    "Mean degree per node is {}\\n\\\n",
    "Diameter of graph is {}\".format(density, mean_degree_pernode, diameter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF vectoriser\n",
    "data_vectoriser = sklearn.feature_extraction.text.TfidfVectorizer(max_df=0.5, max_features=1000, min_df=3, stop_words='english', norm='l2')\n",
    "dataVects = data_vectoriser.fit_transform(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_n(X, max=10):\n",
    "    clusters = []\n",
    "    s_avg = []\n",
    "    for i in range(2, max):\n",
    "        clusterer = sklearn.cluster.KMeans(n_clusters=i, random_state=10)\n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "        silhouette_avg = sklearn.metrics.silhouette_score(X, cluster_labels)\n",
    "        clusters.append(i)\n",
    "        s_avg.append(silhouette_avg)\n",
    "        print(\"For {} clusters, average silhouette score is {}\".format(i, silhouette_avg))\n",
    "    plt.plot(clusters, s_avg)\n",
    "    plt.show()\n",
    "\n",
    "X = dataVects.toarray()\n",
    "find_best_n(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cluster = 5\n",
    "km = sklearn.cluster.KMeans(n_clusters=num_cluster, init='k-means++')\n",
    "km.fit(dataVects)\n",
    "data['kmeans_prediction'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(km, num_cluster, data_vectoriser):\n",
    "    terms = data_vectoriser.get_feature_names()\n",
    "    print(\"Top terms per cluster:\")\n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    for i in range(num_cluster):\n",
    "        print(\"Cluster %d:\" % i)\n",
    "        for ind in order_centroids[i, :20]:\n",
    "            print(' %s' % terms[ind])\n",
    "        print('\\n')\n",
    "\n",
    "get_top_words(km, num_cluster, data_vectoriser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSilhouette(n_clusters, X):\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize = (15,5))\n",
    "    \n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "    clusterer = sklearn.cluster.KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "    \n",
    "    silhouette_avg = sklearn.metrics.silhouette_score(X, cluster_labels)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = sklearn.metrics.silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        cmap = matplotlib.cm.get_cmap(\"nipy_spectral\")\n",
    "        color = cmap(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        y_lower = y_upper + 10\n",
    "    \n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    cmap = matplotlib.cm.get_cmap(\"nipy_spectral\")\n",
    "    colors = cmap(float(i) / n_clusters)\n",
    "    PCA = sklearn.decomposition.PCA\n",
    "    pca = PCA(n_components = 2).fit(dataVects.toarray())\n",
    "    reduced_data = pca.transform(dataVects.toarray())\n",
    "    ax2.scatter(reduced_data[:, 0], reduced_data[:, 1], marker='.', s=30, lw=0, alpha=0.7,\n",
    "                c=colors)\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    projected_centers = pca.transform(centers)\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(projected_centers[:, 0], projected_centers[:, 1],\n",
    "                marker='o', c=\"white\", alpha=1, s=200)\n",
    "    \n",
    "    for i, c in enumerate(projected_centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % i, alpha=1, s=50)\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"PC 1\")    \n",
    "    ax2.set_ylabel(\"PC 2\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    print(\"For n_clusters = {}, The average silhouette_score is : {:.3f}\".format(n_clusters, silhouette_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotSilhouette(num_cluster, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clusters(dataVects, km, num_cluster, terms=data_vectoriser.get_feature_names()):\n",
    "    PCA = sklearn.decomposition.PCA\n",
    "    pca = PCA(n_components = 2).fit(dataVects.toarray())\n",
    "    reduced_data = pca.transform(dataVects.toarray())\n",
    "    # get distinguishing words to label\n",
    "    components = pca.components_\n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    keyword_ids = list(set(order_centroids[:,:10].flatten())) #Get the ids of the most distinguishing words(features) from your kmeans model.\n",
    "    words = [terms[i] for i in keyword_ids]#Turn the ids into words.\n",
    "    x = components[:,keyword_ids][0,:] #Find the coordinates of those words in your biplot.\n",
    "    y = components[:,keyword_ids][1,:]\n",
    "    \n",
    "    cmap = matplotlib.cm.get_cmap(\"nipy_spectral\")\n",
    "    colors_p = [cmap(l/num_cluster) for l in km.labels_]\n",
    "    \n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_frame_on(False)\n",
    "    plt.scatter(reduced_data[:, 0], reduced_data[:, 1], color=colors_p, alpha = 0.5)\n",
    "    for i, word in enumerate(words):\n",
    "        ax.annotate(word, (x[i],y[i]))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.title('Predicted Clusters\\n k = {}'.format(num_cluster))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(dataVects, km, num_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropMissing(wordLst, vocab):\n",
    "    return [w for w in wordLst if w in vocab]\n",
    "\n",
    "data['reduced_tokens'] = data['normalized_words'].apply(lambda x: dropMissing(x, data_vectoriser.vocabulary_.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary\n",
    "dictionary = gensim.corpora.Dictionary(data['reduced_tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in data['reduced_tokens']]\n",
    "# serialize\n",
    "gensim.corpora.MmCorpus.serialize('data.mm', corpus)\n",
    "data_mm = gensim.corpora.MmCorpus('data.mm')\n",
    "# topic modelling\n",
    "topics=10\n",
    "data_lda = gensim.models.ldamodel.LdaModel(corpus=data_mm, id2word=dictionary, num_topics=topics, alpha='auto', eta='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topics(data_lda, dictionary, data, title, n=10):\n",
    "    data_ldaDF = create_lda_df(data_lda, dictionary, data)\n",
    "    data_ldaDFV = data_ldaDF[:n][['topic_%d' %x for x in range(data_lda.num_topics)]]\n",
    "    data_ldaDFVisN = data_ldaDF[:10][['text_id']]\n",
    "    data_ldaDFVis = data_ldaDFV.values\n",
    "    data_ldaDFVisNames = data_ldaDFVisN.values\n",
    "    plot_topics_barchart(data_lda, data_ldaDFVis, data_ldaDFVisNames, title)\n",
    "    return data_ldaDF\n",
    "\n",
    "def create_lda_df(data_lda, dictionary, data):\n",
    "    # create a df of text and topics\n",
    "    data_ldaDF = pandas.DataFrame({\n",
    "                'text_id' : data['text_id'],\n",
    "                'title': data['title'],\n",
    "                'year': data['year'],\n",
    "                'topics' : [data_lda[dictionary.doc2bow(l)] for l in data['reduced_tokens']]\n",
    "        })\n",
    "\n",
    "    #Dict to temporally hold the probabilities\n",
    "    topicsProbDict = {i : [0] * len(data_ldaDF) for i in range(data_lda.num_topics)}\n",
    "\n",
    "    #Load them into the dict\n",
    "    for index, topicTuples in enumerate(data_ldaDF['topics']):\n",
    "        for topicNum, prob in topicTuples:\n",
    "            topicsProbDict[topicNum][index] = prob\n",
    "\n",
    "    #Update the DataFrame\n",
    "    for topicNum in range(data_lda.num_topics):\n",
    "        data_ldaDF['topic_{}'.format(topicNum)] = topicsProbDict[topicNum]\n",
    "    return data_ldaDF\n",
    "\n",
    "\n",
    "def plot_topics_barchart(senlda, ldaDFVis, ldaDFVisNames, title):\n",
    "    N = 10\n",
    "    ind = np.arange(N)\n",
    "    K = senlda.num_topics  # N documents, K topics\n",
    "    ind = np.arange(N)  # the x-axis locations for the novels\n",
    "    width = 0.5  # the width of the bars\n",
    "    plots = []\n",
    "    height_cumulative = np.zeros(N)\n",
    "\n",
    "    for k in range(K):\n",
    "        color = plt.cm.coolwarm(k/K, 1)\n",
    "        if k == 0:\n",
    "            p = plt.bar(ind, ldaDFVis[:, k], width, color=color)\n",
    "        else:\n",
    "            p = plt.bar(ind, ldaDFVis[:, k], width, bottom=height_cumulative, color=color)\n",
    "        height_cumulative += ldaDFVis[:, k]\n",
    "        plots.append(p)\n",
    "\n",
    "\n",
    "    plt.ylim((0, 1))  # proportions sum to 1, so the height of the stacked bars is 1\n",
    "    plt.ylabel('Topics')\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xticks(ind+width/2, ldaDFVisNames, rotation='vertical')\n",
    "\n",
    "    plt.yticks(np.arange(0, 1, 10))\n",
    "    topic_labels = ['Topic #{}'.format(k) for k in range(K)]\n",
    "    plt.legend([p[0] for p in plots], topic_labels, loc='center left', frameon=True,  bbox_to_anchor = (1, .5))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"topics relevant to immigra in first 10 documents\"\n",
    "plot_topics(data_lda, dictionary, data, title, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lda.show_topic(5, topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dynamic topic modelling - long run time (overnight)\n",
    "#docs_per_year = list(data.groupby('year').size())\n",
    "#num_topics = 4\n",
    "#data_ldaseq = ldaseqmodel.LdaSeqModel(corpus=data_mm, id2word=dictionary, time_slice=docs_per_year, num_topics=num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_ldaseq.save(\"data_ldaseq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newspaper_ldaseq.print_topics(time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic distribution divergence\n",
    "\n",
    "from gensim.matutils import kullback_leibler\n",
    "\n",
    "def plot_topic_divergence(data, years, num_topics=5):\n",
    "    topic_prob = get_topic_prob(data, years, num_topics)\n",
    "    L = []\n",
    "    for year_1 in topic_prob.keys():\n",
    "        p = topic_prob[year_1]\n",
    "        l = []\n",
    "        for year_2 in topic_prob.keys():\n",
    "            q = topic_prob[year_2]\n",
    "            l.append(kullback_leibler(p, q))\n",
    "        L.append(l)\n",
    "    M = np.array(L)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    div = pandas.DataFrame(M, columns = list(topic_prob.keys()), index = list(topic_prob.keys()))\n",
    "    ax = sns.heatmap(div)\n",
    "    plt.show()\n",
    "    \n",
    "def get_topic_prob(data, years, num_topics=5):\n",
    "    topic_prob = {}\n",
    "    \n",
    "    byyear = get_topic_distribution(data, years, num_topics)\n",
    "    # Convert to probability\n",
    "    for yr in years:\n",
    "        j=0\n",
    "        for i in range(10):\n",
    "            try:\n",
    "                index, prob = byyear[yr][j]\n",
    "            except IndexError:\n",
    "                index = False\n",
    "\n",
    "            if index == i:\n",
    "                j+=1\n",
    "                if yr in topic_prob:  \n",
    "                    topic_prob[yr].append(prob)\n",
    "                else:\n",
    "                    topic_prob[yr] = [prob]\n",
    "            else:\n",
    "                if yr in topic_prob:  \n",
    "                    topic_prob[yr].append(float(0))\n",
    "                else:\n",
    "                    topic_prob[yr] = [float(0)]\n",
    "    return topic_prob\n",
    "\n",
    "\n",
    "def get_topic_distribution(data, years, num_topics=5):\n",
    "    byyear = {}\n",
    "    # Get topic distribution for each year\n",
    "    for yr in years:\n",
    "        # get all text for each year\n",
    "        text_df = data[data['year']==yr][['text']]\n",
    "        text_df['tokenized_text'] = text_df['text'].apply(lambda x: lucem_illud_2020.word_tokenize(x))\n",
    "        text_df['normalized_tokens'] = text_df['tokenized_text'].apply(lambda x: lucem_illud_2020.normalizeTokens(x))\n",
    "        # create dictionary\n",
    "        data_dictionary_byyear = gensim.corpora.Dictionary(text_df['normalized_tokens'])\n",
    "        data_corpus_byyear = [data_dictionary_byyear.doc2bow(text) for text in text_df['normalized_tokens']]\n",
    "        #lda\n",
    "        lda_byyear = gensim.models.ldamodel.LdaModel(corpus=data_corpus_byyear, id2word=data_dictionary_byyear, num_topics=num_topics, alpha='auto', eta='auto')\n",
    "\n",
    "        # place topic distribution in dictionary\n",
    "        all_text = []\n",
    "        for text in text_df['normalized_tokens']:\n",
    "            all_text.extend(text)\n",
    "        byyear[yr] = lda_byyear[data_dictionary_byyear.doc2bow(all_text)]\n",
    "\n",
    "        print('{} done'.format(yr))\n",
    "    return byyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = sorted(data['year'].unique())\n",
    "plot_topic_divergence(data, years, num_topics=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w2v = gensim.models.word2vec.Word2Vec(data['normalized_sents'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_w2v.save('data_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w2v.most_similar(positive=['immigrants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(data_w2v, numWords):\n",
    "    targetWords = data_w2v.wv.index2word[:numWords]\n",
    "    wordsSubMatrix = []\n",
    "    for word in targetWords:\n",
    "        wordsSubMatrix.append(data_w2v[word])\n",
    "    wordsSubMatrix = np.array(wordsSubMatrix)\n",
    "    pcaWords = sklearn.decomposition.PCA(n_components = 50).fit(wordsSubMatrix)\n",
    "    reducedPCA_data = pcaWords.transform(wordsSubMatrix)\n",
    "    #T-SNE is theoretically better, but you should experiment\n",
    "    tsneWords = sklearn.manifold.TSNE(n_components = 2).fit_transform(reducedPCA_data)\n",
    "    fig = plt.figure(figsize = (10,6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_frame_on(False)\n",
    "    plt.scatter(tsneWords[:, 0], tsneWords[:, 1], alpha = 0)#Making the points invisible \n",
    "    for i, word in enumerate(targetWords):\n",
    "        ax.annotate(word, (tsneWords[:, 0][i],tsneWords[:, 1][i]), size =  20 * (numWords - i) / numWords)\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(data_w2v, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_docs(data):\n",
    "    taggedDocs = []\n",
    "    for index, row in data.iterrows():\n",
    "        #Just doing a simple keyword assignment\n",
    "        docKeywords = [row['year']]\n",
    "        docKeywords.append(row['text_id'])\n",
    "        docKeywords.append(row['genre'])\n",
    "        docKeywords.append(row['title'])\n",
    "        docKeywords.append(row['word_count'])\n",
    "        taggedDocs.append(gensim.models.doc2vec.LabeledSentence(words = row['normalized_words'], tags = docKeywords))\n",
    "    return taggedDocs\n",
    "\n",
    "data['tagged_docs'] = tag_docs(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d2v = gensim.models.doc2vec.Doc2Vec(data['tagged_docs'],size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_d2v.save(\"data_d2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_d2v.most_similar(positive = ['immigrants','illegal'], negative = ['legal'], topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_by_year(data_d2v,years):\n",
    "    for yr in years:\n",
    "        print(yr)\n",
    "        print(data_d2v.most_similar( [ data_d2v.docvecs[yr] ], topn=5))\n",
    "        print()\n",
    "\n",
    "years = range(1990,2016)        \n",
    "most_similar_by_year(data_d2v, years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = list(data['genre'].unique())       \n",
    "most_similar_by_year(data_d2v, genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity(data_d2v, targetDocs):\n",
    "    heatmapMatrixD = []\n",
    "    for tagOuter in targetDocs:\n",
    "        column = []\n",
    "        tagVec = data_d2v.docvecs[tagOuter].reshape(1, -1)\n",
    "        for tagInner in targetDocs:\n",
    "            column.append(sklearn.metrics.pairwise.cosine_similarity(tagVec, data_d2v.docvecs[tagInner].reshape(1, -1))[0][0])\n",
    "        heatmapMatrixD.append(column)\n",
    "    heatmapMatrixD = np.array(heatmapMatrixD)\n",
    "    fig, ax = plt.subplots()\n",
    "    hmap = ax.pcolor(heatmapMatrixD, cmap='terrain')\n",
    "    cbar = plt.colorbar(hmap)\n",
    "\n",
    "    cbar.set_label('cosine similarity', rotation=270)\n",
    "    a = ax.set_xticks(np.arange(heatmapMatrixD.shape[1]) + 0.5, minor=False)\n",
    "    a = ax.set_yticks(np.arange(heatmapMatrixD.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "    a = ax.set_xticklabels(targetDocs, minor=False, rotation=270)\n",
    "    a = ax.set_yticklabels(targetDocs, minor=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity(data_d2v, list(data['year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity(data_d2v, list(data['genre'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_syn0norm(model):\n",
    "    \"\"\"since syn0norm is now depricated\"\"\"\n",
    "    return (model.wv.syn0 / np.sqrt((model.wv.syn0 ** 2).sum(-1))[..., np.newaxis]).astype(np.float32)\n",
    "\n",
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    \"\"\"Procrustes align two gensim word2vec models (to allow for comparison between same word across models).\n",
    "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
    "    (With help from William. Thank you!)\n",
    "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
    "    Then do the alignment on the other_embed model.\n",
    "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
    "    Return other_embed.\n",
    "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
    "    \"\"\"\n",
    "    base_embed = copy.copy(base_embed)\n",
    "    other_embed = copy.copy(other_embed)\n",
    "    # make sure vocabulary and indices are aligned\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "\n",
    "    # get the embedding matrices\n",
    "    base_vecs = calc_syn0norm(in_base_embed)\n",
    "    other_vecs = calc_syn0norm(in_other_embed)\n",
    "\n",
    "    # just a matrix dot product with numpy\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    # SVD method from numpy\n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    # another matrix operation\n",
    "    ortho = u.dot(v) \n",
    "    # Replace original array with modified one\n",
    "    # i.e. multiplying the embedding matrix (syn0norm)by \"ortho\"\n",
    "    other_embed.wv.syn0norm = other_embed.wv.syn0 = (calc_syn0norm(other_embed)).dot(ortho)\n",
    "    return other_embed\n",
    "    \n",
    "def intersection_align_gensim(m1,m2, words=None):\n",
    "    \"\"\"\n",
    "    Intersect two gensim word2vec models, m1 and m2.\n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocab_m1 = set(m1.wv.vocab.keys())\n",
    "    vocab_m2 = set(m2.wv.vocab.keys())\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = vocab_m1&vocab_m2\n",
    "    if words: common_vocab&=set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    if not vocab_m1-common_vocab and not vocab_m2-common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.vocab[w].count + m2.wv.vocab[w].count,reverse=True)\n",
    "\n",
    "    # Then for each model...\n",
    "    for m in [m1,m2]:\n",
    "        # Replace old syn0norm array with new one (with common vocab)\n",
    "        indices = [m.wv.vocab[w].index for w in common_vocab]\n",
    "        old_arr = calc_syn0norm(m)\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.syn0norm = m.wv.syn0 = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        m.index2word = common_vocab\n",
    "        old_vocab = m.wv.vocab\n",
    "        new_vocab = {}\n",
    "        for new_index,word in enumerate(common_vocab):\n",
    "            old_vocab_obj=old_vocab[word]\n",
    "            new_vocab[word] = gensim.models.word2vec.Vocab(index=new_index, count=old_vocab_obj.count)\n",
    "        m.wv.vocab = new_vocab\n",
    "\n",
    "    return (m1,m2)\n",
    "\n",
    "def compareModels(df, category, sort = True):\n",
    "    \"\"\"If you are using time as your category sorting is important\"\"\"\n",
    "    embeddings_raw = {}\n",
    "    cats = sorted(set(df[category]))\n",
    "    for cat in cats:\n",
    "        #This can take a while\n",
    "        print(\"Embedding {}\".format(cat), end = '\\r')\n",
    "        subsetDF = df[df[category] == cat]\n",
    "        #You might want to change the W2V parameters\n",
    "        embeddings_raw[cat] = gensim.models.word2vec.Word2Vec(subsetDF['normalized_sents'].sum())\n",
    "    #These are much quicker\n",
    "    embeddings_aligned = {}\n",
    "    for catOuter in cats:\n",
    "        embeddings_aligned[catOuter] = [embeddings_raw[catOuter]]\n",
    "        for catInner in cats:\n",
    "            embeddings_aligned[catOuter].append(smart_procrustes_align_gensim(embeddings_aligned[catOuter][-1], embeddings_raw[catInner]))\n",
    "    return embeddings_raw, embeddings_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rawEmbeddings, data_comparedEmbeddings = compareModels(data, 'year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDivergenceDF(word, embeddingsDict):\n",
    "    dists = []\n",
    "    cats = sorted(set(embeddingsDict.keys()))\n",
    "    dists = {}\n",
    "    print(word)\n",
    "    for cat in cats:\n",
    "        dists[cat] = []\n",
    "        for embed in embeddingsDict[cat][1:]:\n",
    "            dists[cat].append(np.abs(1 - sklearn.metrics.pairwise.cosine_similarity(np.expand_dims(embeddingsDict[cat][0][word], axis = 0),\n",
    "                                                                             np.expand_dims(embed[word], axis = 0))[0,0]))\n",
    "    return pandas.DataFrame(dists, index = cats)\n",
    "\n",
    "def plot_divergence(targetWord, comparedEmbeddings):\n",
    "    pltDF = getDivergenceDF(targetWord, comparedEmbeddings)\n",
    "    fig, ax = plt.subplots(figsize = (10, 7))\n",
    "    sns.heatmap(pltDF, ax = ax, annot = False) #set annot True for a lot more information\n",
    "    ax.set_xlabel(\"Starting year\")\n",
    "    ax.set_ylabel(\"Final year\")\n",
    "    ax.set_ylabel(\"Final year\")\n",
    "    ax.set_title(\"Yearly linguistic change for: '{}'\".format(targetWord))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_divergence('immigrants', data_comparedEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_divergence('immigration', data_comparedEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_divergence('mexico', data_comparedEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_divergence('border', data_comparedEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDivergence(word, embeddingsDict):\n",
    "    cats = sorted(set(embeddingsDict.keys()))\n",
    "    \n",
    "    dists = []\n",
    "    for embed in embeddingsDict[cats[0]][1:]:\n",
    "        dists.append(1 - sklearn.metrics.pairwise.cosine_similarity(np.expand_dims(embeddingsDict[cats[0]][0][word], axis = 0), np.expand_dims(embed[word], axis = 0))[0,0])\n",
    "    return sum(dists)\n",
    "\n",
    "def findMostDivergent(embeddingsDict):\n",
    "    words = []\n",
    "    for embeds in embeddingsDict.values():\n",
    "        for embed in embeds:\n",
    "            words += list(embed.wv.vocab.keys())\n",
    "    words = set(words)\n",
    "    print(\"Found {} words to compare\".format(len(words)))\n",
    "    return sorted([(w, findDivergence(w, embeddingsDict)) for w in words], key = lambda x: x[1], reverse=True)\n",
    "\n",
    "data_wordDivergences = findMostDivergent(data_comparedEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most divergence\n",
    "data_wordDivergences[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# least divergence\n",
    "data_wordDivergences[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1",
   "language": "python",
   "name": "3.8.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
