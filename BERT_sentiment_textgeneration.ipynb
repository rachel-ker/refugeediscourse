{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/refugee_coca_foranalysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nlp = spacy.load(\"en\")\n",
    "except OSError:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def sent_tokenize(word_list, model=nlp):\n",
    "    doc = model(word_list)\n",
    "    sentences = [sent.string.strip() for sent in doc.sents]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentences'] = data['text'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5-year periods\n",
    "def get_period(year, startyr, endyr, n=5):\n",
    "    period_start = []\n",
    "    for i in range(startyr, endyr+1, n):\n",
    "        period_start.append(i)\n",
    "    for index, p in enumerate(period_start):\n",
    "        if year >= p:\n",
    "            period = index\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return period  \n",
    "    \n",
    "data['period'] = data['year'].apply(lambda x: get_period(x, 1991, 2015, n=5) if x>=1991 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate a pipeline for sentiment-analysis\n",
    "nlp_sentiment = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = data.period.unique()\n",
    "\n",
    "sentiment_over_period = {}\n",
    "sentiment_scores = []\n",
    "for p in periods:\n",
    "    data_period = data[data['period'] == p]\n",
    "    for sent in data_period['sentences'].sum():\n",
    "        if 'refugee' in sent: \n",
    "            sentiment = nlp_sentiment(sent)\n",
    "            polarity = sentiment['label']\n",
    "            score = sentiment['score']\n",
    "            \n",
    "            if polarity=='NEGATIVE':\n",
    "                score = -score\n",
    "            \n",
    "            sentiment_scores.append(score)\n",
    "    avg = sum(sentiment_scores) / len(sentiment_scores)\n",
    "    sentiment_over_period[p] = avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_over_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textgen_results(sequence)\n",
    "    refugees_textgen = {}\n",
    "    tokenizer_gpt = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "    model_gpt = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "\n",
    "    input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "    generated = model_gpt.generate(input, max_length=50)\n",
    "    resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "    refugees_textgen['gpt'] = resulting_string\n",
    "\n",
    "    for ideology in ['left','right']:\n",
    "        for period in range(0,5):\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\"bertresults/output_gpt_period{}_{}\".format(period, ideology))\n",
    "            model = AutoModelWithLMHead.from_pretrained(\"bertresults/output_gpt_period{}_{}\".format(period, ideology))\n",
    "\n",
    "            input = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "            generated = model.generate(input, max_length=50)\n",
    "            resulting_string = tokenizer.decode(generated.tolist()[0])\n",
    "\n",
    "            refugees_textgen['period{}_{}'.format(period, ideology)] = resulting_string\n",
    "    return refugees_textgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refugees_textgen = textgen_results(\"Refugees are\")\n",
    "refugees_textgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 with Pytorch",
   "language": "python",
   "name": "cca-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
